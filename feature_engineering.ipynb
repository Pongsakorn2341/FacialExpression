{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "df = pd.read_csv(cwd + \"/data_csv/preprocessing_data.csv\")\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image\n",
       "emotion       \n",
       "0         2129\n",
       "1         2015\n",
       "2           73\n",
       "3           65\n",
       "4           32\n",
       "5            6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame(train, columns=[\"image\", \"emotion\"])\n",
    "dictionary = {'emotion':{'HAPPINESS': 0,'NEUTRAL': 1, 'SURPRISE': 2, 'ANGER': 3, 'SADNESS': 4, 'DISGUST': 5}}\n",
    "train.replace(dictionary, inplace = True)\n",
    "train.to_csv(cwd + \"/data_csv/train.csv\")\n",
    "\n",
    "train.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image\n",
       "emotion       \n",
       "0          230\n",
       "1          221\n",
       "2           13\n",
       "3           13\n",
       "4            4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(test, columns=[\"image\", \"emotion\"])\n",
    "dictionary = {'emotion':{'HAPPINESS': 0,'NEUTRAL': 1, 'SURPRISE': 2, 'ANGER': 3, 'SADNESS': 4, 'DISGUST': 5}}\n",
    "test.replace(dictionary, inplace = True)\n",
    "test.to_csv(cwd + \"/data_csv/test.csv\")\n",
    "\n",
    "test.groupby('emotion').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport cv2,matplotlib.pyplot as plt,dlib,imutils\\nfrom imutils import face_utils\\n\\ndetector = dlib.get_frontal_face_detector()\\npredictor = dlib.shape_predictor(\"../input/dlib-68/shape_predictor_68_face_landmarks.dat\")\\n\\nimage=plt.imread(\"../input/recognizing-faces-in-the-wild/train/F0002/MID1/P00009_face3.jpg\")\\n# image = imutils.resize(image, width=500)\\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\nrects = detector(gray, 1)\\n\\nfor rect in rects:\\n    pred=predictor(gray,rect)\\n    fig, ax1 = plt.subplots()\\n\\n    ax1.imshow(image)\\n    ax1.scatter(face_utils.shape_to_np(pred)[:,0],face_utils.shape_to_np(pred)[:,1])\\n    \\n# del predictor\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import cv2,matplotlib.pyplot as plt,dlib,imutils\n",
    "from imutils import face_utils\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"../input/dlib-68/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "image=plt.imread(\"../input/recognizing-faces-in-the-wild/train/F0002/MID1/P00009_face3.jpg\")\n",
    "# image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "rects = detector(gray, 1)\n",
    "\n",
    "for rect in rects:\n",
    "    pred=predictor(gray,rect)\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax1.scatter(face_utils.shape_to_np(pred)[:,0],face_utils.shape_to_np(pred)[:,1])\n",
    "    \n",
    "# del predictor\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.feature_selection import SelectKBest\\nfrom sklearn.feature_selection import chi2\\n\\ndata = pd.read_csv(cwd + \"/train_data.csv\")\\n\\n#independent columns\\nX = data.iloc[:,0:20]\\n\\n#target column\\ny = data.iloc[:,-1]  \\n\\n#apply SelectKBest class to extract top 10 best features\\nbestfeatures = SelectKBest(score_func=chi2, k=10)\\nfit = bestfeatures.fit(X,y)\\ndfscores = pd.DataFrame(fit.scores_)\\ndfcolumns = pd.DataFrame(X.columns)\\n\\n#concat two dataframes for better visualization \\nfeatureScores = pd.concat([dfcolumns, dfscores],axis=1)\\n\\n#naming the dataframe columns\\nfeatureScores.columns = [\\'Specs\\',\\'Score\\']\\n\\n#print 10 best features\\nprint(featureScores.nlargest(10,\\'Score\\'))\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "data = pd.read_csv(cwd + \"/train_data.csv\")\n",
    "\n",
    "#independent columns\n",
    "X = data.iloc[:,0:20]\n",
    "\n",
    "#target column\n",
    "y = data.iloc[:,-1]  \n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns, dfscores],axis=1)\n",
    "\n",
    "#naming the dataframe columns\n",
    "featureScores.columns = ['Specs','Score']\n",
    "\n",
    "#print 10 best features\n",
    "print(featureScores.nlargest(10,'Score'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n",
      "Length x :  68\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39m# loop over the face detections\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mfor\u001b[39;00m (i, rect) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(rects):\n\u001b[1;32m     34\u001b[0m     \u001b[39m# determine the facial landmarks and convert the facial landmark (x, y)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     shape \u001b[39m=\u001b[39m predictor(image, rect)\n\u001b[1;32m     36\u001b[0m     shape \u001b[39m=\u001b[39m face_utils\u001b[39m.\u001b[39mshape_to_np(shape)\n\u001b[1;32m     38\u001b[0m     \u001b[39m# loop over coordinates, draw them on the image and store coordinates in two lists\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2, math, numpy as np, dlib\n",
    "from imutils import face_utils\n",
    "\n",
    "# emotion list\n",
    "emotions = [0, 1, 2, 3, 4, 5] \n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(cwd + \"/predictor/shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "error = 0\n",
    "\n",
    "mlist = []\n",
    "distlist = []\n",
    "left_eye_list = []\n",
    "right_eye_list = []\n",
    "# run each image in train\n",
    "def get_distance(fist_point, second_point):\n",
    "    distance =  math.sqrt(math.pow(fist_point[0] - second_point[1], 2) + math.pow(fist_point[0] - second_point[1], 2))\n",
    "    return abs(distance)\n",
    "for idx, row in df.iterrows():\n",
    "    imagePath = cwd + \"/cleaned_images/\" + row.image\n",
    "    image = cv2.imread(imagePath)\n",
    "\n",
    "    rects = detector(image, 0)\n",
    "\n",
    "    if len(rects) == 0:\n",
    "        error += 1\n",
    "        print(row.image)\n",
    "\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks and convert the facial landmark (x, y)\n",
    "        shape = predictor(image, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "        # loop over coordinates, draw them on the image and store coordinates in two lists\n",
    "        for (x, y) in shape:\n",
    "            cv2.circle(image, (x, y), 2, (0, 255, 0), -1)\n",
    "            # cv2.imshow(\"Output\", image)\n",
    "            xlist.append(x)\n",
    "            ylist.append(y)\n",
    "\n",
    "    # get mean of both axes to determine centre of gravity\n",
    "    xmean = np.mean(xlist) \n",
    "    ymean = np.mean(ylist)\n",
    "\n",
    "    # plot central face on image\n",
    "    cv2.circle(image, (int(xmean), int(ymean)), 1, (0, 255, 0), -1)\n",
    "\n",
    "    # find distance between mouth\n",
    "    mavg = np.mean([abs(ylist[61] - ylist[67]), abs(ylist[62] - ylist[66]), abs(ylist[63] - ylist[65])])\n",
    "    mlist.append(mavg)\n",
    "\n",
    "    # find distance between left eye\n",
    "    left_eye_avg = np.mean([\n",
    "        get_distance([xlist[36], ylist[36]], [xlist[39], ylist[39]]),\n",
    "        get_distance([xlist[37], ylist[37]], [xlist[40], ylist[40]]),\n",
    "        get_distance([xlist[38], ylist[38]], [xlist[41], ylist[41]])\n",
    "    ])\n",
    "    left_eye_list.append(left_eye_avg)\n",
    "    right_eye_avg = np.mean([\n",
    "        get_distance([xlist[42], ylist[42]], [xlist[45], ylist[45]]),\n",
    "        get_distance([xlist[43], ylist[43]], [xlist[46], ylist[46]]),\n",
    "        get_distance([xlist[44], ylist[44]], [xlist[47], ylist[47]])\n",
    "    ])\n",
    "    right_eye_list.append(right_eye_avg)\n",
    "\n",
    "    # find distance between every point to central point\n",
    "    templist = []\n",
    "    for i in range(18, 68):\n",
    "        dist = math.sqrt(math.pow(xlist[i] - xmean, 2) + math.pow(ylist[i] - ymean, 2))\n",
    "        templist.append(dist)\n",
    "    distavg = np.mean(dist)\n",
    "    distlist.append(distavg)\n",
    "  \n",
    "    # show the output image with the face detections + facial landmarks\n",
    "    # cv2.imshow(\"Output\", image)\n",
    "    # k = cv2.waitKey(5) & 0xFF\n",
    "    # if k == 68:\n",
    "    #     break\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mouth_distance'] = mlist\n",
    "df['average_distance'] = distlist\n",
    "df['left_eye_distance'] = left_eye_list\n",
    "df['right_eye_distance'] = right_eye_list\n",
    "\n",
    "df.to_csv(cwd + \"/data_csv/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      average_distance  left_eye_distance  mouth_distance  right_eye_distance\n",
      "3890         71.049238          70.239274       47.000000           96.637927\n",
      "3830         68.125484          41.955002       22.333333          123.036580\n",
      "3260         76.380040          69.296465        3.333333          151.792256\n",
      "676          47.694269         100.409163        6.666667          131.521861\n",
      "3909         75.372882          74.010510        8.333333          123.507984\n",
      "...                ...                ...             ...                 ...\n",
      "3430         63.673640          74.481914       13.666667          128.222030\n",
      "3650         60.692559          55.154329        1.333333          107.951635\n",
      "547          77.154938          57.982756       30.333333          118.322535\n",
      "120          78.329970          40.540789       26.333333          111.251467\n",
      "2590         75.460514          60.339779        8.666667          129.636243\n",
      "\n",
      "[4320 rows x 4 columns]\n",
      "(4320, 4) (4320,)\n",
      "(3888, 4) (3888,)\n",
      "(432, 4) (432,)\n",
      "0.5416666666666666\n",
      "0.5254629629629629\n",
      "0.5347222222222222\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as p\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[df.columns.difference(['emotion', 'image'])]\n",
    "y = df.loc[:,'emotion']\n",
    "print(X)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=0.1, random_state=0)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_validate.shape, y_validate.shape)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_validate, y_validate))\n",
    "\n",
    "clf = svm.SVC(kernel='poly', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_validate, y_validate))\n",
    "\n",
    "clf = svm.SVC(kernel='rbf', C=1).fit(X_train, y_train)\n",
    "print(clf.score(X_validate, y_validate))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4d02cdae7faed44485a20a1dfe89a6c1f0576f684e5ae49a964539fc51d957e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
