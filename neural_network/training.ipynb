{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "\n",
    "# train data\n",
    "cwd = os.getcwd()\n",
    "epochs = 100\n",
    "df = pd.read_csv(cwd + '/state/train.csv')\n",
    "X = list(df['image'][i] for i in range(len(df)))\n",
    "y = list(df['emotion'][i] for i in range(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.8591824644549764, 1: 2.264939376443418, 2: 1.8262918994413408, 3: 1.857421875, 4: 0.4784577387486279, 5: 0.41608771743742046, 6: 1.4797717842323652, 7: 1.3063186813186813}\n"
     ]
    }
   ],
   "source": [
    "weight = dict(enumerate(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)))\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createModel():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (img_size[0],img_size[1],3)) ,\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(), \n",
    "        tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
    "        tf.keras.layers.Dropout(0.1,seed = 2019),\n",
    "        tf.keras.layers.Dense(400,activation =\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.3,seed = 2019),\n",
    "        tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.4,seed = 2019),\n",
    "        tf.keras.layers.Dense(200,activation =\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.2,seed = 2019),\n",
    "        tf.keras.layers.Dense(5,activation = \"softmax\")   #Adding the Output Layer\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True),  # tf.keras.optimizers.Adam(amsgrad=True),  # tf.keras.optimizers.SGD(nesterov=True), # tfa.optimizers.RectifiedAdam(),\n",
    "            loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                from_logits=True),\n",
    "            metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_accuracy', patience=epochs*0.05, restore_best_weights=True)\n",
    "# cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath=\"model/cp-{epoch:04d}.ckpt\",\n",
    "#     verbose=0,\n",
    "#     save_weights_only=True,\n",
    "#     monitor='val_accuracy',\n",
    "#     save_best_only=True)\n",
    "# tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "#     log_dir=\"./logs\",\n",
    "#             update_freq=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 222, 222, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 111, 111, 16)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 109, 109, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 54, 54, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 52, 52, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 26, 26, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 12, 12, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 550)               10138150  \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 550)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 400)               220400    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 300)               120300    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 5)                 1005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,637,495\n",
      "Trainable params: 10,637,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "adam=Adam(lr=0.001)\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2, shutil\n",
    "df_train = pd.read_csv(cwd + \"\\\\state\\\\train.csv\")\n",
    "df_test = pd.read_csv(cwd + \"\\\\state\\\\test.csv\")\n",
    "output_train_dir = cwd + \"\\\\train\"\n",
    "root_image_dir = cwd + \"\\\\cleaned_images\\\\\"\n",
    "dictionary = ['ANGER', 'CONTEMPT', 'DISGUST', 'FEAR', 'HAPPINESS',  'NEUTRAL', 'SADNESS', 'SURPRISE']\n",
    "dir_test = cwd + \"\\\\test\\\\\"\n",
    "dir_train = cwd + \"\\\\train\\\\\"\n",
    "if(os.path.exists(dir_train) or os.path.exists(dir_test)):\n",
    "    shutil.rmtree(dir_train)\n",
    "    shutil.rmtree(dir_test)\n",
    "for emotion in dictionary:\n",
    "    os.makedirs(dir_test + \"\\\\\" + emotion)\n",
    "    os.makedirs(dir_train + \"\\\\\" + emotion)\n",
    "\n",
    "def isInDir(image_dir):\n",
    "    return len(image_dir.split(\"/\")) >= 2\n",
    "for index, row in df_test.iterrows():\n",
    "    if(isInDir(row['image']) == False): continue\n",
    "    output_test_dir = dir_test + row['image']\n",
    "    image = cv2.imread(root_image_dir + row['image'])\n",
    "    cv2.imwrite(output_test_dir, image)\n",
    "for index, row in df_train.iterrows():\n",
    "    if(isInDir(row['image']) == False): continue\n",
    "    output_train_dir = dir_train + row['image']\n",
    "    image = cv2.imread(root_image_dir + row['image'])\n",
    "    cv2.imwrite(output_train_dir, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20279 images belonging to 8 classes.\n",
      "Found 2499 images belonging to 8 classes.\n",
      "Found 20279 files belonging to 8 classes.\n",
      "Found 2499 files belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "bs = 30\n",
    "train_dir = cwd + \"\\\\train\"\n",
    "test_dir = cwd + \"\\\\test\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(img_size[0],img_size[1]))\n",
    "validation_generator =  test_datagen.flow_from_directory(test_dir,\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         target_size=(img_size[0],img_size[1]))\n",
    "dictionary = ['ANGER', 'CONTEMPT', 'DISGUST', 'FEAR', 'HAPPINESS',  'NEUTRAL', 'SADNESS', 'SURPRISE']\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    shuffle=True,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=img_size,\n",
    "    class_names=dictionary,\n",
    "    color_mode='rgb',\n",
    "    batch_size=bs)\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=img_size,\n",
    "    class_names=dictionary,\n",
    "    color_mode='rgb',\n",
    "    batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', patience=epochs*0.05, restore_best_weights=True)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"model/cp-{epoch:04d}.ckpt\",\n",
    "    verbose=0,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./logs\",\n",
    "            update_freq=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Local\\Temp\\ipykernel_9000\\1634376334.py\", line 1, in <cell line: 1>\n      history = model.fit(train_generator,\n    File \"C:\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1862, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5202, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [30,5] and labels shape [240]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_11451]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Pongsakorn\\OneDrive\\Desktop\\Working\\FacialLandMarks\\facial_cleandata\\neural_network\\training.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000009?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000009?line=1'>2</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39;49mvalidation_generator,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000009?line=2'>3</a>\u001b[0m                     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39m150\u001b[39;49m \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m bs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000009?line=3'>4</a>\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000009?line=4'>5</a>\u001b[0m                     validation_steps\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m bs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000009?line=5'>6</a>\u001b[0m                     verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> <a href='file:///c%3A/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Python39/lib/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Python39/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"C:\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 473, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 462, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 369, in dispatch_shell\n      await result\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\kernelbase.py\", line 664, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\ipkernel.py\", line 355, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\ipykernel\\zmqshell.py\", line 532, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2854, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 2900, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3301, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Pongsakorn\\AppData\\Roaming\\Python\\Python39\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Pongsakorn\\AppData\\Local\\Temp\\ipykernel_9000\\1634376334.py\", line 1, in <cell line: 1>\n      history = model.fit(train_generator,\n    File \"C:\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Python39\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Python39\\lib\\site-packages\\keras\\losses.py\", line 1862, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"C:\\Python39\\lib\\site-packages\\keras\\backend.py\", line 5202, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nlogits and labels must have the same first dimension, got logits shape [30,5] and labels shape [240]\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_11451]"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=150 // bs,\n",
    "                    epochs=30,\n",
    "                    validation_steps=50 // bs,\n",
    "                    verbose=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "186c8c6637da87bf1b48281a4203551e6bea7fd5e6b5755ebb6ce2cf054369ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
