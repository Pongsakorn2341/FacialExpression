{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "import tensorflow as tf\n",
    "#import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224, 224)\n",
    "\n",
    "# train data\n",
    "cwd = os.getcwd()\n",
    "epochs = 100\n",
    "df = pd.read_csv(cwd + '/state/train.csv')\n",
    "X = list(df['image'][i] for i in range(len(df)))\n",
    "y = list(df['emotion'][i] for i in range(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.8591824644549764, 1: 2.264939376443418, 2: 1.8262918994413408, 3: 1.857421875, 4: 0.4784577387486279, 5: 0.41608771743742046, 6: 1.4797717842323652, 7: 1.3063186813186813}\n"
     ]
    }
   ],
   "source": [
    "weight = dict(enumerate(class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)))\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def createModel():\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(16,(3,3),activation = \"relu\" , input_shape = (img_size[0],img_size[1],3)) ,\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\") ,  \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(64,(3,3),activation = \"relu\") ,  \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Conv2D(128,(3,3),activation = \"relu\"),  \n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Flatten(), \n",
    "        tf.keras.layers.Dense(550,activation=\"relu\"),      #Adding the Hidden layer\n",
    "        tf.keras.layers.Dropout(0.1,seed = 2019),\n",
    "        tf.keras.layers.Dense(400,activation =\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.3,seed = 2019),\n",
    "        tf.keras.layers.Dense(300,activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.4,seed = 2019),\n",
    "        tf.keras.layers.Dense(200,activation =\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.2,seed = 2019),\n",
    "        tf.keras.layers.Dense(5,activation = \"softmax\")   #Adding the Output Layer\n",
    "    ])\n",
    "    # model.compile(optimizer=tf.keras.optimizers.Adam(amsgrad=True),  # tf.keras.optimizers.Adam(amsgrad=True),  # tf.keras.optimizers.SGD(nesterov=True), # tfa.optimizers.RectifiedAdam(),\n",
    "    #         loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    #             from_logits=True),\n",
    "    #         metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', patience=epochs*0.05, restore_best_weights=True)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"model/cp-{epoch:04d}.ckpt\",\n",
    "    verbose=0,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True)\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=\"./logs\",\n",
    "            update_freq=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 222, 222, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 111, 111, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 109, 109, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 54, 54, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 52, 52, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 26, 26, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 550)               10138150  \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 550)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 400)               220400    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 400)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 300)               120300    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 300)               0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 200)               60200     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 5)                 1005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,637,495\n",
      "Trainable params: 10,637,495\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,SGD,Adam\n",
    "adam=Adam(lr=0.001)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Pongsakorn\\OneDrive\\Desktop\\Working\\FacialLandMarks\\facial_cleandata\\neural_network\\training.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000010?line=20'>21</a>\u001b[0m output_train_dir \u001b[39m=\u001b[39m dir_train \u001b[39m+\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000010?line=21'>22</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(root_image_dir \u001b[39m+\u001b[39m row[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Pongsakorn/OneDrive/Desktop/Working/FacialLandMarks/facial_cleandata/neural_network/training.ipynb#ch0000010?line=22'>23</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimwrite(output_train_dir, image)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, cv2, shutil\n",
    "df_train = pd.read_csv(cwd + \"\\\\state\\\\train.csv\")\n",
    "df_test = pd.read_csv(cwd + \"\\\\state\\\\test.csv\")\n",
    "output_train_dir = cwd + \"\\\\train\"\n",
    "root_image_dir = cwd + \"\\\\cleaned_images\\\\\"\n",
    "dictionary = ['ANGER', 'CONTEMPT', 'DISGUST', 'FEAR', 'HAPPINESS',  'NEUTRAL', 'SADNESS', 'SURPRISE']\n",
    "dir_test = cwd + \"\\\\test\\\\\"\n",
    "dir_train = cwd + \"\\\\train\\\\\"\n",
    "if(os.path.exists(dir_train) or os.path.exists(dir_test)):\n",
    "    shutil.rmtree(dir_train)\n",
    "    shutil.rmtree(dir_test)\n",
    "for emotion in dictionary:\n",
    "    os.makedirs(dir_test + \"\\\\\" + emotion)\n",
    "    os.makedirs(dir_train + \"\\\\\" + emotion)\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    output_test_dir = dir_test + row['image']\n",
    "    image = cv2.imread(root_image_dir + row['image'])\n",
    "    cv2.imwrite(output_test_dir, image)\n",
    "for index, row in df_train.iterrows():\n",
    "    output_train_dir = dir_train + row['image']\n",
    "    image = cv2.imread(root_image_dir + row['image'])\n",
    "    cv2.imwrite(output_train_dir, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2499 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "bs = 30\n",
    "train_dir = cwd + \"\\\\state\\\\train.csv\"\n",
    "test_dir = cwd + \"\\\\test\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
    "# train_generator=train_datagen.flow_from_directory(train_dir,batch_size=bs,class_mode='categorical',target_size=(img_size[0],img_size[1]))\n",
    "validation_generator =  test_datagen.flow_from_directory(test_dir,\n",
    "                                                         batch_size=bs,\n",
    "                                                         class_mode  = 'categorical',\n",
    "                                                         target_size=(img_size[0],img_size[1]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "186c8c6637da87bf1b48281a4203551e6bea7fd5e6b5755ebb6ce2cf054369ca"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
