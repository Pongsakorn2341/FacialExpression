{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "import cv2, imutils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from hyperopt.pyll.base import scope \n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "pre_csv = os.path.abspath(os.path.join(os.sep, cwd, '..', 'neural_network', 'augmentation_data.csv'))\n",
    "df = pd.read_csv(pre_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFullImagePath(full_path):\n",
    "    sub_image_path = full_path\n",
    "    split_sub_image_path = sub_image_path.split(\"/\")\n",
    "    image_path = \"\"\n",
    "    if(len(split_sub_image_path) == 2):\n",
    "        image_path = os.path.abspath(os.path.join(os.sep, cwd, \"..\", \"neural_network\", \"augmentation\", split_sub_image_path[0], split_sub_image_path[1]))\n",
    "    else:\n",
    "        image_path = os.path.abspath(os.path.join(os.sep, cwd, \"..\", \"neural_network\", \"augmentation\", sub_image_path))\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 10000/77205\n",
      "[INFO] processed 20000/77205\n",
      "[INFO] processed 30000/77205\n",
      "[INFO] processed 40000/77205\n",
      "[INFO] processed 50000/77205\n",
      "[INFO] processed 60000/77205\n",
      "[INFO] processed 70000/77205\n",
      "[9948, 8812, 9692, 10002, 10001, 10001, 10001, 8748]\n"
     ]
    }
   ],
   "source": [
    "count = [0 for x in range(8)]\n",
    "raw_images =  []\n",
    "labels = []\n",
    "for i, row in df.iterrows():\n",
    "    image_path = getFullImagePath(row.image)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (112, 112), interpolation = cv2.INTER_AREA)\n",
    "    pixels = image.flatten()\n",
    "    raw_images.append(pixels)\n",
    "    \n",
    "    label = row.emotion\n",
    "    labels.append(label)\n",
    "    \n",
    "    count[row.emotion] += 1\n",
    "    if i > 0 and i % 10000 == 0: print('[INFO] processed {}/{}'.format(i, len(df)))\n",
    "    \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'rate'       : hp.uniform('rate', 0.01, 0.5),\n",
    "    'dropout'    : hp.uniform('dropout', 0.01, 0.5),\n",
    "    'units1'      : scope.int(hp.quniform('units1', 10, 100, 5)),\n",
    "    'units2'      : scope.int(hp.quniform('units2', 10, 100, 5)),\n",
    "    'units3'      : scope.int(hp.quniform('units3', 10, 100, 5)),\n",
    "    'units4'      : scope.int(hp.quniform('units4', 10, 100, 5)),\n",
    "    'batch_size' : scope.int(hp.quniform('batch_size', 100, 250, 25)),\n",
    "    'layers'     : scope.int(hp.quniform('layers', 3, 4, 1)),\n",
    "    'optimizer'  : hp.choice('optimizer', ['adam', 'adadelta', 'sgd', 'RMSprop']),\n",
    "    'epochs'     : scope.int(hp.quniform('epochs', 100, 300, 10)),\n",
    "    'activation' : hp.choice('activation', ['relu']), # ['relu', 'sigmoid', 'tanh', 'elu']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_nn(params):\n",
    "    print(\"params\", params)\n",
    "\n",
    "    # Keras LSTM model\n",
    "    model = Sequential()\n",
    "\n",
    "    # params['layers'] => num of hidden layer\n",
    "\n",
    "    if params['layers'] == 1:\n",
    "        model.add(Dense(params['units1'], activation=params['activation'], input_shape=(X_train.shape[1],)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        #model.add(Dropout(rate=params['rate']))\n",
    "    else:\n",
    "        # First layer specifies input_shape and returns sequences\n",
    "        model.add(Dense(params['units1'], activation=params['activation'], input_shape=(X_train.shape[1],)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        #model.add(Dropout(rate=params['rate']))\n",
    "\n",
    "        # Middle layers return sequences\n",
    "        for i in range(params['layers']-2):\n",
    "            model.add(Dense(params['units' + str(i + 2)], activation=params['activation']))\n",
    "            model.add(keras.layers.BatchNormalization())\n",
    "            #model.add(Dropout(rate=params['rate']))\n",
    "\n",
    "        # Last layer doesn't return anything                                            \n",
    "        model.add(Dense(params['units' + str(params['layers'])], activation=params['activation']))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(Dropout(rate=params['rate']))\n",
    "\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(optimizer=params['optimizer'], loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss',mode='min', verbose=1,patience=15)\n",
    "    result =  model.fit(X_train, y_train, validation_data=(X_val, y_val,), batch_size=params['batch_size'], epochs=int(X_train.shape[0]/best_params['batch_size']), verbose=0)\n",
    "\n",
    "    # Get the lowest validation loss of the training epochs\n",
    "    validation_loss = np.amin(result.history['val_loss']) \n",
    "    print('Best validation loss of epoch:', validation_loss)\n",
    "\n",
    "    return {'loss': validation_loss, \n",
    "            'status': STATUS_OK, \n",
    "            'model': model, \n",
    "            'params': params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(raw_images), np.array(labels), test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "y_val = le.transform(y_val)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "trials = Trials()\n",
    "best = fmin(f_nn, \n",
    "            space, \n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50,\n",
    "            trials=trials)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = trials.results[np.argmin([r['loss'] for r in trials.results])]['model']\n",
    "best_params = trials.results[np.argmin([r['loss'] for r in trials.results])]['params']\n",
    "worst_model = trials.results[np.argmax([r['loss'] for r in trials.results])]['model']\n",
    "worst_params = trials.results[np.argmax([r['loss'] for r in trials.results])]['params']\n",
    "\n",
    "print(best_model)\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(activation = 'relu'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation=activation))\n",
    "    model.add(Dense(128, activation=activation))\n",
    "    model.add(Dense(64, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation=activation))\n",
    "    model.add(Dense(16, activation=activation))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(len(lb.classes_), activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_model_best_param(params, output):\n",
    "    model = Sequential()\n",
    "    if params['layers'] == 1:\n",
    "        model.add(Dense(params['units1'], activation=params['activation'], input_shape=(X_train.shape[1],)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        #model.add(Dropout(rate=params['rate']))\n",
    "    else:\n",
    "        # First layer specifies input_shape and returns sequences\n",
    "        model.add(Dense(params['units1'], activation=params['activation'], input_shape=(X_train.shape[1],)))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        #model.add(Dropout(rate=params['rate']))\n",
    "\n",
    "        # Middle layers return sequences\n",
    "        for i in range(params['layers']-2):\n",
    "            model.add(Dense(params['units' + str(i + 2)], activation=params['activation']))\n",
    "            model.add(keras.layers.BatchNormalization())\n",
    "            #model.add(Dropout(rate=params['rate']))\n",
    "\n",
    "        # Last layer doesn't return anything                                            \n",
    "        model.add(Dense(params['units' + str(params['layers'])], activation=params['activation']))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(Dropout(rate=params['rate']))\n",
    "        \n",
    "    model.compile(optimizer=params['optimizer'], loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_52 (Dense)             (None, 100)               3763300   \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 45)                4545      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 45)                180       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 45)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 8)                 368       \n",
      "=================================================================\n",
      "Total params: 3,779,293\n",
      "Trainable params: 3,778,803\n",
      "Non-trainable params: 490\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# without augmentation\n",
    "# best_params = {'activation': 'relu', 'batch_size': 125, 'dropout': 0.022269352793562694, 'epochs': 190, 'layers': 4, 'optimizer': 'adadelta', 'rate': 0.341066733379372, 'units1': 70, 'units2': 55, 'units3': 40, 'units4': 25}\n",
    "\n",
    "# with augmentation\n",
    "best_params = {'activation': 'relu', 'batch_size': 225, 'dropout': 0.43494195542218583, 'epochs': 210, 'layers': 3, 'optimizer': 'adadelta', 'rate': 0.3152384932786021, 'units1': 100, 'units2': 100, 'units3': 45, 'units4': 80}\n",
    "\n",
    "model = create_model_best_param(best_params, 8)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/277\n",
      "278/278 - 12s - loss: 0.1304 - accuracy: 0.1448 - val_loss: 0.1196 - val_accuracy: 0.1702\n",
      "Epoch 2/277\n",
      "278/278 - 10s - loss: 0.1263 - accuracy: 0.1687 - val_loss: 0.1175 - val_accuracy: 0.1950\n",
      "Epoch 3/277\n",
      "278/278 - 10s - loss: 0.1237 - accuracy: 0.1828 - val_loss: 0.1157 - val_accuracy: 0.2069\n",
      "Epoch 4/277\n",
      "278/278 - 10s - loss: 0.1218 - accuracy: 0.1953 - val_loss: 0.1131 - val_accuracy: 0.2213\n",
      "Epoch 5/277\n",
      "278/278 - 10s - loss: 0.1203 - accuracy: 0.2068 - val_loss: 0.1116 - val_accuracy: 0.2315\n",
      "Epoch 6/277\n",
      "278/278 - 10s - loss: 0.1187 - accuracy: 0.2142 - val_loss: 0.1099 - val_accuracy: 0.2469\n",
      "Epoch 7/277\n",
      "278/278 - 10s - loss: 0.1173 - accuracy: 0.2242 - val_loss: 0.1089 - val_accuracy: 0.2526\n",
      "Epoch 8/277\n",
      "278/278 - 11s - loss: 0.1162 - accuracy: 0.2329 - val_loss: 0.1077 - val_accuracy: 0.2600\n",
      "Epoch 9/277\n",
      "278/278 - 10s - loss: 0.1150 - accuracy: 0.2413 - val_loss: 0.1066 - val_accuracy: 0.2677\n",
      "Epoch 10/277\n",
      "278/278 - 11s - loss: 0.1140 - accuracy: 0.2483 - val_loss: 0.1057 - val_accuracy: 0.2773\n",
      "Epoch 11/277\n",
      "278/278 - 10s - loss: 0.1132 - accuracy: 0.2544 - val_loss: 0.1053 - val_accuracy: 0.2796\n",
      "Epoch 12/277\n",
      "278/278 - 11s - loss: 0.1124 - accuracy: 0.2625 - val_loss: 0.1045 - val_accuracy: 0.2907\n",
      "Epoch 13/277\n",
      "278/278 - 11s - loss: 0.1116 - accuracy: 0.2670 - val_loss: 0.1039 - val_accuracy: 0.2923\n",
      "Epoch 14/277\n",
      "278/278 - 10s - loss: 0.1108 - accuracy: 0.2735 - val_loss: 0.1031 - val_accuracy: 0.3012\n",
      "Epoch 15/277\n",
      "278/278 - 11s - loss: 0.1101 - accuracy: 0.2774 - val_loss: 0.1026 - val_accuracy: 0.3046\n",
      "Epoch 16/277\n",
      "278/278 - 11s - loss: 0.1098 - accuracy: 0.2795 - val_loss: 0.1021 - val_accuracy: 0.3098\n",
      "Epoch 17/277\n",
      "278/278 - 10s - loss: 0.1089 - accuracy: 0.2857 - val_loss: 0.1015 - val_accuracy: 0.3104\n",
      "Epoch 18/277\n",
      "278/278 - 11s - loss: 0.1085 - accuracy: 0.2898 - val_loss: 0.1011 - val_accuracy: 0.3185\n",
      "Epoch 19/277\n",
      "278/278 - 11s - loss: 0.1083 - accuracy: 0.2929 - val_loss: 0.1008 - val_accuracy: 0.3175\n",
      "Epoch 20/277\n",
      "278/278 - 11s - loss: 0.1077 - accuracy: 0.2948 - val_loss: 0.1006 - val_accuracy: 0.3223\n",
      "Epoch 21/277\n",
      "278/278 - 11s - loss: 0.1072 - accuracy: 0.2992 - val_loss: 0.1004 - val_accuracy: 0.3258\n",
      "Epoch 22/277\n",
      "278/278 - 10s - loss: 0.1068 - accuracy: 0.3033 - val_loss: 0.0997 - val_accuracy: 0.3252\n",
      "Epoch 23/277\n",
      "278/278 - 10s - loss: 0.1061 - accuracy: 0.3094 - val_loss: 0.0998 - val_accuracy: 0.3267\n",
      "Epoch 24/277\n",
      "278/278 - 11s - loss: 0.1058 - accuracy: 0.3112 - val_loss: 0.0993 - val_accuracy: 0.3334\n",
      "Epoch 25/277\n",
      "278/278 - 11s - loss: 0.1057 - accuracy: 0.3139 - val_loss: 0.0990 - val_accuracy: 0.3380\n",
      "Epoch 26/277\n",
      "278/278 - 11s - loss: 0.1052 - accuracy: 0.3154 - val_loss: 0.0987 - val_accuracy: 0.3395\n",
      "Epoch 27/277\n",
      "278/278 - 11s - loss: 0.1048 - accuracy: 0.3190 - val_loss: 0.0987 - val_accuracy: 0.3405\n",
      "Epoch 28/277\n",
      "278/278 - 11s - loss: 0.1043 - accuracy: 0.3222 - val_loss: 0.0981 - val_accuracy: 0.3429\n",
      "Epoch 29/277\n",
      "278/278 - 11s - loss: 0.1041 - accuracy: 0.3231 - val_loss: 0.0980 - val_accuracy: 0.3442\n",
      "Epoch 30/277\n",
      "278/278 - 11s - loss: 0.1037 - accuracy: 0.3277 - val_loss: 0.0977 - val_accuracy: 0.3435\n",
      "Epoch 31/277\n",
      "278/278 - 10s - loss: 0.1036 - accuracy: 0.3266 - val_loss: 0.0978 - val_accuracy: 0.3506\n",
      "Epoch 32/277\n",
      "278/278 - 10s - loss: 0.1032 - accuracy: 0.3297 - val_loss: 0.0970 - val_accuracy: 0.3531\n",
      "Epoch 33/277\n",
      "278/278 - 10s - loss: 0.1028 - accuracy: 0.3354 - val_loss: 0.0973 - val_accuracy: 0.3526\n",
      "Epoch 34/277\n",
      "278/278 - 11s - loss: 0.1026 - accuracy: 0.3350 - val_loss: 0.0968 - val_accuracy: 0.3570\n",
      "Epoch 35/277\n",
      "278/278 - 10s - loss: 0.1022 - accuracy: 0.3389 - val_loss: 0.0968 - val_accuracy: 0.3586\n",
      "Epoch 36/277\n",
      "278/278 - 10s - loss: 0.1021 - accuracy: 0.3411 - val_loss: 0.0965 - val_accuracy: 0.3625\n",
      "Epoch 37/277\n",
      "278/278 - 10s - loss: 0.1017 - accuracy: 0.3415 - val_loss: 0.0968 - val_accuracy: 0.3588\n",
      "Epoch 38/277\n",
      "278/278 - 10s - loss: 0.1014 - accuracy: 0.3453 - val_loss: 0.0960 - val_accuracy: 0.3671\n",
      "Epoch 39/277\n",
      "278/278 - 10s - loss: 0.1013 - accuracy: 0.3467 - val_loss: 0.0961 - val_accuracy: 0.3664\n",
      "Epoch 40/277\n",
      "278/278 - 10s - loss: 0.1011 - accuracy: 0.3475 - val_loss: 0.0959 - val_accuracy: 0.3675\n",
      "Epoch 41/277\n",
      "278/278 - 10s - loss: 0.1007 - accuracy: 0.3486 - val_loss: 0.0956 - val_accuracy: 0.3668\n",
      "Epoch 42/277\n",
      "278/278 - 10s - loss: 0.1005 - accuracy: 0.3513 - val_loss: 0.0954 - val_accuracy: 0.3694\n",
      "Epoch 43/277\n",
      "278/278 - 10s - loss: 0.1000 - accuracy: 0.3565 - val_loss: 0.0951 - val_accuracy: 0.3723\n",
      "Epoch 44/277\n",
      "278/278 - 10s - loss: 0.0999 - accuracy: 0.3570 - val_loss: 0.0957 - val_accuracy: 0.3714\n",
      "Epoch 45/277\n",
      "278/278 - 10s - loss: 0.0999 - accuracy: 0.3596 - val_loss: 0.0949 - val_accuracy: 0.3726\n",
      "Epoch 46/277\n",
      "278/278 - 10s - loss: 0.0995 - accuracy: 0.3606 - val_loss: 0.0948 - val_accuracy: 0.3772\n",
      "Epoch 47/277\n",
      "278/278 - 10s - loss: 0.0994 - accuracy: 0.3606 - val_loss: 0.0948 - val_accuracy: 0.3799\n",
      "Epoch 48/277\n",
      "278/278 - 10s - loss: 0.0993 - accuracy: 0.3622 - val_loss: 0.0944 - val_accuracy: 0.3799\n",
      "Epoch 49/277\n",
      "278/278 - 10s - loss: 0.0990 - accuracy: 0.3626 - val_loss: 0.0942 - val_accuracy: 0.3809\n",
      "Epoch 50/277\n",
      "278/278 - 10s - loss: 0.0986 - accuracy: 0.3669 - val_loss: 0.0942 - val_accuracy: 0.3847\n",
      "Epoch 51/277\n",
      "278/278 - 10s - loss: 0.0987 - accuracy: 0.3670 - val_loss: 0.0941 - val_accuracy: 0.3849\n",
      "Epoch 52/277\n",
      "278/278 - 10s - loss: 0.0984 - accuracy: 0.3691 - val_loss: 0.0942 - val_accuracy: 0.3851\n",
      "Epoch 53/277\n",
      "278/278 - 10s - loss: 0.0980 - accuracy: 0.3707 - val_loss: 0.0941 - val_accuracy: 0.3841\n",
      "Epoch 54/277\n",
      "278/278 - 10s - loss: 0.0979 - accuracy: 0.3734 - val_loss: 0.0934 - val_accuracy: 0.3894\n",
      "Epoch 55/277\n",
      "278/278 - 10s - loss: 0.0976 - accuracy: 0.3761 - val_loss: 0.0933 - val_accuracy: 0.3885\n",
      "Epoch 56/277\n",
      "278/278 - 10s - loss: 0.0974 - accuracy: 0.3757 - val_loss: 0.0939 - val_accuracy: 0.3877\n",
      "Epoch 57/277\n",
      "278/278 - 10s - loss: 0.0973 - accuracy: 0.3768 - val_loss: 0.0931 - val_accuracy: 0.3911\n",
      "Epoch 58/277\n",
      "278/278 - 10s - loss: 0.0972 - accuracy: 0.3773 - val_loss: 0.0931 - val_accuracy: 0.3906\n",
      "Epoch 59/277\n",
      "278/278 - 10s - loss: 0.0969 - accuracy: 0.3809 - val_loss: 0.0930 - val_accuracy: 0.3919\n",
      "Epoch 60/277\n",
      "278/278 - 10s - loss: 0.0968 - accuracy: 0.3829 - val_loss: 0.0932 - val_accuracy: 0.3920\n",
      "Epoch 61/277\n",
      "278/278 - 11s - loss: 0.0966 - accuracy: 0.3836 - val_loss: 0.0925 - val_accuracy: 0.3985\n",
      "Epoch 62/277\n",
      "278/278 - 12s - loss: 0.0965 - accuracy: 0.3845 - val_loss: 0.0928 - val_accuracy: 0.3973\n",
      "Epoch 63/277\n",
      "278/278 - 11s - loss: 0.0963 - accuracy: 0.3853 - val_loss: 0.0931 - val_accuracy: 0.3930\n",
      "Epoch 64/277\n",
      "278/278 - 11s - loss: 0.0961 - accuracy: 0.3864 - val_loss: 0.0932 - val_accuracy: 0.3926\n",
      "Epoch 65/277\n",
      "278/278 - 11s - loss: 0.0961 - accuracy: 0.3871 - val_loss: 0.0919 - val_accuracy: 0.4021\n",
      "Epoch 66/277\n",
      "278/278 - 12s - loss: 0.0957 - accuracy: 0.3881 - val_loss: 0.0922 - val_accuracy: 0.3969\n",
      "Epoch 67/277\n",
      "278/278 - 12s - loss: 0.0954 - accuracy: 0.3924 - val_loss: 0.0918 - val_accuracy: 0.4039\n",
      "Epoch 68/277\n",
      "278/278 - 11s - loss: 0.0952 - accuracy: 0.3933 - val_loss: 0.0917 - val_accuracy: 0.4029\n",
      "Epoch 69/277\n",
      "278/278 - 11s - loss: 0.0951 - accuracy: 0.3949 - val_loss: 0.0921 - val_accuracy: 0.4006\n",
      "Epoch 70/277\n",
      "278/278 - 11s - loss: 0.0948 - accuracy: 0.3957 - val_loss: 0.0919 - val_accuracy: 0.4039\n",
      "Epoch 71/277\n",
      "278/278 - 11s - loss: 0.0945 - accuracy: 0.4004 - val_loss: 0.0914 - val_accuracy: 0.4124\n",
      "Epoch 72/277\n",
      "278/278 - 11s - loss: 0.0945 - accuracy: 0.3976 - val_loss: 0.0916 - val_accuracy: 0.4065\n",
      "Epoch 73/277\n",
      "278/278 - 11s - loss: 0.0943 - accuracy: 0.4015 - val_loss: 0.0913 - val_accuracy: 0.4067\n",
      "Epoch 74/277\n",
      "278/278 - 11s - loss: 0.0945 - accuracy: 0.3987 - val_loss: 0.0912 - val_accuracy: 0.4042\n",
      "Epoch 75/277\n",
      "278/278 - 11s - loss: 0.0938 - accuracy: 0.4042 - val_loss: 0.0913 - val_accuracy: 0.4121\n",
      "Epoch 76/277\n",
      "278/278 - 12s - loss: 0.0941 - accuracy: 0.4024 - val_loss: 0.0912 - val_accuracy: 0.4060\n",
      "Epoch 77/277\n",
      "278/278 - 11s - loss: 0.0940 - accuracy: 0.4032 - val_loss: 0.0911 - val_accuracy: 0.4146\n",
      "Epoch 78/277\n",
      "278/278 - 11s - loss: 0.0938 - accuracy: 0.4038 - val_loss: 0.0909 - val_accuracy: 0.4119\n",
      "Epoch 79/277\n",
      "278/278 - 11s - loss: 0.0934 - accuracy: 0.4083 - val_loss: 0.0911 - val_accuracy: 0.4116\n",
      "Epoch 80/277\n",
      "278/278 - 11s - loss: 0.0934 - accuracy: 0.4075 - val_loss: 0.0907 - val_accuracy: 0.4126\n",
      "Epoch 81/277\n",
      "278/278 - 12s - loss: 0.0933 - accuracy: 0.4075 - val_loss: 0.0903 - val_accuracy: 0.4168\n",
      "Epoch 82/277\n",
      "278/278 - 11s - loss: 0.0930 - accuracy: 0.4112 - val_loss: 0.0905 - val_accuracy: 0.4163\n",
      "Epoch 83/277\n",
      "278/278 - 11s - loss: 0.0930 - accuracy: 0.4119 - val_loss: 0.0907 - val_accuracy: 0.4140\n",
      "Epoch 84/277\n",
      "278/278 - 11s - loss: 0.0926 - accuracy: 0.4154 - val_loss: 0.0906 - val_accuracy: 0.4156\n",
      "Epoch 85/277\n",
      "278/278 - 11s - loss: 0.0925 - accuracy: 0.4152 - val_loss: 0.0903 - val_accuracy: 0.4199\n",
      "Epoch 86/277\n",
      "278/278 - 11s - loss: 0.0925 - accuracy: 0.4147 - val_loss: 0.0904 - val_accuracy: 0.4188\n",
      "Epoch 87/277\n",
      "278/278 - 11s - loss: 0.0925 - accuracy: 0.4132 - val_loss: 0.0902 - val_accuracy: 0.4218\n",
      "Epoch 88/277\n",
      "278/278 - 11s - loss: 0.0920 - accuracy: 0.4180 - val_loss: 0.0897 - val_accuracy: 0.4245\n",
      "Epoch 89/277\n",
      "278/278 - 11s - loss: 0.0922 - accuracy: 0.4155 - val_loss: 0.0895 - val_accuracy: 0.4257\n",
      "Epoch 90/277\n",
      "278/278 - 11s - loss: 0.0920 - accuracy: 0.4174 - val_loss: 0.0902 - val_accuracy: 0.4234\n",
      "Epoch 91/277\n",
      "278/278 - 11s - loss: 0.0919 - accuracy: 0.4202 - val_loss: 0.0892 - val_accuracy: 0.4311\n",
      "Epoch 92/277\n",
      "278/278 - 11s - loss: 0.0914 - accuracy: 0.4239 - val_loss: 0.0892 - val_accuracy: 0.4280\n",
      "Epoch 93/277\n",
      "278/278 - 11s - loss: 0.0918 - accuracy: 0.4214 - val_loss: 0.0893 - val_accuracy: 0.4258\n",
      "Epoch 94/277\n",
      "278/278 - 11s - loss: 0.0913 - accuracy: 0.4228 - val_loss: 0.0895 - val_accuracy: 0.4255\n",
      "Epoch 95/277\n",
      "278/278 - 11s - loss: 0.0912 - accuracy: 0.4248 - val_loss: 0.0890 - val_accuracy: 0.4277\n",
      "Epoch 96/277\n",
      "278/278 - 11s - loss: 0.0911 - accuracy: 0.4268 - val_loss: 0.0889 - val_accuracy: 0.4294\n",
      "Epoch 97/277\n",
      "278/278 - 11s - loss: 0.0909 - accuracy: 0.4272 - val_loss: 0.0889 - val_accuracy: 0.4297\n",
      "Epoch 98/277\n",
      "278/278 - 11s - loss: 0.0906 - accuracy: 0.4294 - val_loss: 0.0888 - val_accuracy: 0.4288\n",
      "Epoch 99/277\n",
      "278/278 - 11s - loss: 0.0905 - accuracy: 0.4309 - val_loss: 0.0890 - val_accuracy: 0.4291\n",
      "Epoch 100/277\n",
      "278/278 - 11s - loss: 0.0905 - accuracy: 0.4312 - val_loss: 0.0887 - val_accuracy: 0.4303\n",
      "Epoch 101/277\n",
      "278/278 - 11s - loss: 0.0905 - accuracy: 0.4308 - val_loss: 0.0886 - val_accuracy: 0.4296\n",
      "Epoch 102/277\n",
      "278/278 - 11s - loss: 0.0902 - accuracy: 0.4342 - val_loss: 0.0883 - val_accuracy: 0.4323\n",
      "Epoch 103/277\n",
      "278/278 - 11s - loss: 0.0902 - accuracy: 0.4339 - val_loss: 0.0885 - val_accuracy: 0.4357\n",
      "Epoch 104/277\n",
      "278/278 - 11s - loss: 0.0899 - accuracy: 0.4335 - val_loss: 0.0884 - val_accuracy: 0.4346\n",
      "Epoch 105/277\n",
      "278/278 - 11s - loss: 0.0897 - accuracy: 0.4366 - val_loss: 0.0882 - val_accuracy: 0.4350\n",
      "Epoch 106/277\n",
      "278/278 - 11s - loss: 0.0897 - accuracy: 0.4377 - val_loss: 0.0879 - val_accuracy: 0.4383\n",
      "Epoch 107/277\n",
      "278/278 - 11s - loss: 0.0895 - accuracy: 0.4373 - val_loss: 0.0880 - val_accuracy: 0.4409\n",
      "Epoch 108/277\n",
      "278/278 - 11s - loss: 0.0897 - accuracy: 0.4367 - val_loss: 0.0879 - val_accuracy: 0.4396\n",
      "Epoch 109/277\n",
      "278/278 - 11s - loss: 0.0893 - accuracy: 0.4411 - val_loss: 0.0883 - val_accuracy: 0.4349\n",
      "Epoch 110/277\n",
      "278/278 - 11s - loss: 0.0892 - accuracy: 0.4398 - val_loss: 0.0880 - val_accuracy: 0.4376\n",
      "Epoch 111/277\n",
      "278/278 - 11s - loss: 0.0891 - accuracy: 0.4432 - val_loss: 0.0880 - val_accuracy: 0.4421\n",
      "Epoch 112/277\n",
      "278/278 - 11s - loss: 0.0887 - accuracy: 0.4433 - val_loss: 0.0874 - val_accuracy: 0.4422\n",
      "Epoch 113/277\n",
      "278/278 - 11s - loss: 0.0886 - accuracy: 0.4460 - val_loss: 0.0875 - val_accuracy: 0.4406\n",
      "Epoch 114/277\n",
      "278/278 - 11s - loss: 0.0884 - accuracy: 0.4483 - val_loss: 0.0875 - val_accuracy: 0.4427\n",
      "Epoch 115/277\n",
      "278/278 - 11s - loss: 0.0885 - accuracy: 0.4446 - val_loss: 0.0873 - val_accuracy: 0.4464\n",
      "Epoch 116/277\n",
      "278/278 - 11s - loss: 0.0885 - accuracy: 0.4472 - val_loss: 0.0872 - val_accuracy: 0.4464\n",
      "Epoch 117/277\n",
      "278/278 - 11s - loss: 0.0881 - accuracy: 0.4494 - val_loss: 0.0875 - val_accuracy: 0.4470\n",
      "Epoch 118/277\n",
      "278/278 - 11s - loss: 0.0881 - accuracy: 0.4489 - val_loss: 0.0871 - val_accuracy: 0.4450\n",
      "Epoch 119/277\n",
      "278/278 - 11s - loss: 0.0880 - accuracy: 0.4516 - val_loss: 0.0870 - val_accuracy: 0.4467\n",
      "Epoch 120/277\n",
      "278/278 - 11s - loss: 0.0878 - accuracy: 0.4535 - val_loss: 0.0873 - val_accuracy: 0.4455\n",
      "Epoch 121/277\n",
      "278/278 - 11s - loss: 0.0878 - accuracy: 0.4527 - val_loss: 0.0870 - val_accuracy: 0.4480\n",
      "Epoch 122/277\n",
      "278/278 - 11s - loss: 0.0876 - accuracy: 0.4547 - val_loss: 0.0868 - val_accuracy: 0.4467\n",
      "Epoch 123/277\n",
      "278/278 - 11s - loss: 0.0874 - accuracy: 0.4547 - val_loss: 0.0869 - val_accuracy: 0.4483\n",
      "Epoch 124/277\n",
      "278/278 - 11s - loss: 0.0875 - accuracy: 0.4549 - val_loss: 0.0870 - val_accuracy: 0.4461\n",
      "Epoch 125/277\n",
      "278/278 - 11s - loss: 0.0875 - accuracy: 0.4543 - val_loss: 0.0865 - val_accuracy: 0.4539\n",
      "Epoch 126/277\n",
      "278/278 - 11s - loss: 0.0873 - accuracy: 0.4556 - val_loss: 0.0871 - val_accuracy: 0.4471\n",
      "Epoch 127/277\n",
      "278/278 - 11s - loss: 0.0872 - accuracy: 0.4566 - val_loss: 0.0864 - val_accuracy: 0.4529\n",
      "Epoch 128/277\n",
      "278/278 - 11s - loss: 0.0871 - accuracy: 0.4565 - val_loss: 0.0864 - val_accuracy: 0.4526\n",
      "Epoch 129/277\n",
      "278/278 - 11s - loss: 0.0868 - accuracy: 0.4593 - val_loss: 0.0867 - val_accuracy: 0.4539\n",
      "Epoch 130/277\n",
      "278/278 - 11s - loss: 0.0867 - accuracy: 0.4604 - val_loss: 0.0859 - val_accuracy: 0.4614\n",
      "Epoch 131/277\n",
      "278/278 - 11s - loss: 0.0865 - accuracy: 0.4626 - val_loss: 0.0863 - val_accuracy: 0.4546\n",
      "Epoch 132/277\n",
      "278/278 - 11s - loss: 0.0865 - accuracy: 0.4620 - val_loss: 0.0860 - val_accuracy: 0.4578\n",
      "Epoch 133/277\n",
      "278/278 - 10s - loss: 0.0863 - accuracy: 0.4623 - val_loss: 0.0861 - val_accuracy: 0.4545\n",
      "Epoch 134/277\n",
      "278/278 - 10s - loss: 0.0861 - accuracy: 0.4641 - val_loss: 0.0861 - val_accuracy: 0.4530\n",
      "Epoch 135/277\n",
      "278/278 - 10s - loss: 0.0858 - accuracy: 0.4667 - val_loss: 0.0857 - val_accuracy: 0.4605\n",
      "Epoch 136/277\n",
      "278/278 - 10s - loss: 0.0860 - accuracy: 0.4650 - val_loss: 0.0858 - val_accuracy: 0.4569\n",
      "Epoch 137/277\n",
      "278/278 - 10s - loss: 0.0858 - accuracy: 0.4662 - val_loss: 0.0856 - val_accuracy: 0.4585\n",
      "Epoch 138/277\n",
      "278/278 - 10s - loss: 0.0857 - accuracy: 0.4669 - val_loss: 0.0854 - val_accuracy: 0.4642\n",
      "Epoch 139/277\n",
      "278/278 - 10s - loss: 0.0857 - accuracy: 0.4691 - val_loss: 0.0863 - val_accuracy: 0.4559\n",
      "Epoch 140/277\n",
      "278/278 - 10s - loss: 0.0856 - accuracy: 0.4684 - val_loss: 0.0852 - val_accuracy: 0.4609\n",
      "Epoch 141/277\n",
      "278/278 - 10s - loss: 0.0856 - accuracy: 0.4687 - val_loss: 0.0852 - val_accuracy: 0.4654\n",
      "Epoch 142/277\n",
      "278/278 - 10s - loss: 0.0853 - accuracy: 0.4697 - val_loss: 0.0854 - val_accuracy: 0.4601\n",
      "Epoch 143/277\n",
      "278/278 - 10s - loss: 0.0854 - accuracy: 0.4701 - val_loss: 0.0852 - val_accuracy: 0.4664\n",
      "Epoch 144/277\n",
      "278/278 - 10s - loss: 0.0851 - accuracy: 0.4736 - val_loss: 0.0852 - val_accuracy: 0.4644\n",
      "Epoch 145/277\n",
      "278/278 - 10s - loss: 0.0852 - accuracy: 0.4710 - val_loss: 0.0849 - val_accuracy: 0.4686\n",
      "Epoch 146/277\n",
      "278/278 - 10s - loss: 0.0849 - accuracy: 0.4742 - val_loss: 0.0855 - val_accuracy: 0.4602\n",
      "Epoch 147/277\n",
      "278/278 - 9s - loss: 0.0847 - accuracy: 0.4752 - val_loss: 0.0849 - val_accuracy: 0.4701\n",
      "Epoch 148/277\n",
      "278/278 - 10s - loss: 0.0848 - accuracy: 0.4760 - val_loss: 0.0849 - val_accuracy: 0.4687\n",
      "Epoch 149/277\n",
      "278/278 - 10s - loss: 0.0842 - accuracy: 0.4787 - val_loss: 0.0848 - val_accuracy: 0.4671\n",
      "Epoch 150/277\n",
      "278/278 - 10s - loss: 0.0843 - accuracy: 0.4782 - val_loss: 0.0847 - val_accuracy: 0.4681\n",
      "Epoch 151/277\n",
      "278/278 - 10s - loss: 0.0843 - accuracy: 0.4779 - val_loss: 0.0845 - val_accuracy: 0.4742\n",
      "Epoch 152/277\n",
      "278/278 - 10s - loss: 0.0843 - accuracy: 0.4791 - val_loss: 0.0846 - val_accuracy: 0.4704\n",
      "Epoch 153/277\n",
      "278/278 - 10s - loss: 0.0840 - accuracy: 0.4807 - val_loss: 0.0844 - val_accuracy: 0.4710\n",
      "Epoch 154/277\n",
      "278/278 - 11s - loss: 0.0839 - accuracy: 0.4833 - val_loss: 0.0844 - val_accuracy: 0.4713\n",
      "Epoch 155/277\n",
      "278/278 - 11s - loss: 0.0839 - accuracy: 0.4840 - val_loss: 0.0841 - val_accuracy: 0.4723\n",
      "Epoch 156/277\n",
      "278/278 - 11s - loss: 0.0837 - accuracy: 0.4851 - val_loss: 0.0843 - val_accuracy: 0.4753\n",
      "Epoch 157/277\n",
      "278/278 - 10s - loss: 0.0836 - accuracy: 0.4841 - val_loss: 0.0844 - val_accuracy: 0.4717\n",
      "Epoch 158/277\n",
      "278/278 - 10s - loss: 0.0837 - accuracy: 0.4829 - val_loss: 0.0839 - val_accuracy: 0.4745\n",
      "Epoch 159/277\n",
      "278/278 - 10s - loss: 0.0837 - accuracy: 0.4855 - val_loss: 0.0840 - val_accuracy: 0.4772\n",
      "Epoch 160/277\n",
      "278/278 - 10s - loss: 0.0832 - accuracy: 0.4871 - val_loss: 0.0841 - val_accuracy: 0.4749\n",
      "Epoch 161/277\n",
      "278/278 - 10s - loss: 0.0832 - accuracy: 0.4889 - val_loss: 0.0836 - val_accuracy: 0.4779\n",
      "Epoch 162/277\n",
      "278/278 - 10s - loss: 0.0831 - accuracy: 0.4879 - val_loss: 0.0839 - val_accuracy: 0.4733\n",
      "Epoch 163/277\n",
      "278/278 - 10s - loss: 0.0830 - accuracy: 0.4887 - val_loss: 0.0842 - val_accuracy: 0.4729\n",
      "Epoch 164/277\n",
      "278/278 - 10s - loss: 0.0830 - accuracy: 0.4896 - val_loss: 0.0839 - val_accuracy: 0.4755\n",
      "Epoch 165/277\n",
      "278/278 - 10s - loss: 0.0830 - accuracy: 0.4883 - val_loss: 0.0836 - val_accuracy: 0.4768\n",
      "Epoch 166/277\n",
      "278/278 - 10s - loss: 0.0828 - accuracy: 0.4899 - val_loss: 0.0836 - val_accuracy: 0.4792\n",
      "Epoch 167/277\n",
      "278/278 - 10s - loss: 0.0827 - accuracy: 0.4895 - val_loss: 0.0837 - val_accuracy: 0.4781\n",
      "Epoch 168/277\n",
      "278/278 - 11s - loss: 0.0825 - accuracy: 0.4939 - val_loss: 0.0834 - val_accuracy: 0.4765\n",
      "Epoch 169/277\n",
      "278/278 - 10s - loss: 0.0824 - accuracy: 0.4945 - val_loss: 0.0831 - val_accuracy: 0.4851\n",
      "Epoch 170/277\n",
      "278/278 - 10s - loss: 0.0823 - accuracy: 0.4937 - val_loss: 0.0834 - val_accuracy: 0.4841\n",
      "Epoch 171/277\n",
      "278/278 - 10s - loss: 0.0823 - accuracy: 0.4943 - val_loss: 0.0834 - val_accuracy: 0.4805\n",
      "Epoch 172/277\n",
      "278/278 - 10s - loss: 0.0819 - accuracy: 0.4974 - val_loss: 0.0836 - val_accuracy: 0.4804\n",
      "Epoch 173/277\n",
      "278/278 - 10s - loss: 0.0821 - accuracy: 0.4957 - val_loss: 0.0834 - val_accuracy: 0.4827\n",
      "Epoch 174/277\n",
      "278/278 - 10s - loss: 0.0819 - accuracy: 0.4975 - val_loss: 0.0832 - val_accuracy: 0.4877\n",
      "Epoch 175/277\n",
      "278/278 - 10s - loss: 0.0817 - accuracy: 0.4997 - val_loss: 0.0833 - val_accuracy: 0.4844\n",
      "Epoch 176/277\n",
      "278/278 - 10s - loss: 0.0818 - accuracy: 0.4987 - val_loss: 0.0828 - val_accuracy: 0.4894\n",
      "Epoch 177/277\n",
      "278/278 - 10s - loss: 0.0817 - accuracy: 0.4977 - val_loss: 0.0830 - val_accuracy: 0.4827\n",
      "Epoch 178/277\n",
      "278/278 - 10s - loss: 0.0814 - accuracy: 0.5001 - val_loss: 0.0829 - val_accuracy: 0.4881\n",
      "Epoch 179/277\n",
      "278/278 - 10s - loss: 0.0816 - accuracy: 0.4997 - val_loss: 0.0827 - val_accuracy: 0.4894\n",
      "Epoch 180/277\n",
      "278/278 - 10s - loss: 0.0814 - accuracy: 0.5018 - val_loss: 0.0826 - val_accuracy: 0.4896\n",
      "Epoch 181/277\n",
      "278/278 - 10s - loss: 0.0813 - accuracy: 0.5015 - val_loss: 0.0828 - val_accuracy: 0.4867\n",
      "Epoch 182/277\n",
      "278/278 - 10s - loss: 0.0808 - accuracy: 0.5071 - val_loss: 0.0825 - val_accuracy: 0.4878\n",
      "Epoch 183/277\n",
      "278/278 - 10s - loss: 0.0810 - accuracy: 0.5049 - val_loss: 0.0825 - val_accuracy: 0.4891\n",
      "Epoch 184/277\n",
      "278/278 - 10s - loss: 0.0810 - accuracy: 0.5041 - val_loss: 0.0825 - val_accuracy: 0.4923\n",
      "Epoch 185/277\n",
      "278/278 - 10s - loss: 0.0811 - accuracy: 0.5026 - val_loss: 0.0825 - val_accuracy: 0.4857\n",
      "Epoch 186/277\n",
      "278/278 - 10s - loss: 0.0806 - accuracy: 0.5068 - val_loss: 0.0821 - val_accuracy: 0.4940\n",
      "Epoch 187/277\n",
      "278/278 - 10s - loss: 0.0809 - accuracy: 0.5039 - val_loss: 0.0824 - val_accuracy: 0.4913\n",
      "Epoch 188/277\n",
      "278/278 - 10s - loss: 0.0805 - accuracy: 0.5082 - val_loss: 0.0822 - val_accuracy: 0.4922\n",
      "Epoch 189/277\n",
      "278/278 - 10s - loss: 0.0805 - accuracy: 0.5083 - val_loss: 0.0822 - val_accuracy: 0.4947\n",
      "Epoch 190/277\n",
      "278/278 - 10s - loss: 0.0803 - accuracy: 0.5110 - val_loss: 0.0821 - val_accuracy: 0.4922\n",
      "Epoch 191/277\n",
      "278/278 - 11s - loss: 0.0803 - accuracy: 0.5101 - val_loss: 0.0821 - val_accuracy: 0.4890\n",
      "Epoch 192/277\n",
      "278/278 - 10s - loss: 0.0802 - accuracy: 0.5098 - val_loss: 0.0822 - val_accuracy: 0.4942\n",
      "Epoch 193/277\n",
      "278/278 - 10s - loss: 0.0802 - accuracy: 0.5094 - val_loss: 0.0824 - val_accuracy: 0.4893\n",
      "Epoch 194/277\n",
      "278/278 - 10s - loss: 0.0801 - accuracy: 0.5098 - val_loss: 0.0818 - val_accuracy: 0.4963\n",
      "Epoch 195/277\n",
      "278/278 - 10s - loss: 0.0797 - accuracy: 0.5148 - val_loss: 0.0822 - val_accuracy: 0.4932\n",
      "Epoch 196/277\n",
      "278/278 - 10s - loss: 0.0798 - accuracy: 0.5137 - val_loss: 0.0817 - val_accuracy: 0.4985\n",
      "Epoch 197/277\n",
      "278/278 - 10s - loss: 0.0795 - accuracy: 0.5162 - val_loss: 0.0818 - val_accuracy: 0.4955\n",
      "Epoch 198/277\n",
      "278/278 - 10s - loss: 0.0796 - accuracy: 0.5151 - val_loss: 0.0815 - val_accuracy: 0.4998\n",
      "Epoch 199/277\n",
      "278/278 - 10s - loss: 0.0795 - accuracy: 0.5153 - val_loss: 0.0814 - val_accuracy: 0.4972\n",
      "Epoch 200/277\n",
      "278/278 - 10s - loss: 0.0794 - accuracy: 0.5170 - val_loss: 0.0813 - val_accuracy: 0.5006\n",
      "Epoch 201/277\n",
      "278/278 - 10s - loss: 0.0794 - accuracy: 0.5160 - val_loss: 0.0818 - val_accuracy: 0.4991\n",
      "Epoch 202/277\n",
      "278/278 - 10s - loss: 0.0790 - accuracy: 0.5183 - val_loss: 0.0812 - val_accuracy: 0.5002\n",
      "Epoch 203/277\n",
      "278/278 - 10s - loss: 0.0792 - accuracy: 0.5182 - val_loss: 0.0813 - val_accuracy: 0.4995\n",
      "Epoch 204/277\n",
      "278/278 - 10s - loss: 0.0790 - accuracy: 0.5199 - val_loss: 0.0811 - val_accuracy: 0.5022\n",
      "Epoch 205/277\n",
      "278/278 - 10s - loss: 0.0787 - accuracy: 0.5209 - val_loss: 0.0811 - val_accuracy: 0.5017\n",
      "Epoch 206/277\n",
      "278/278 - 10s - loss: 0.0789 - accuracy: 0.5205 - val_loss: 0.0810 - val_accuracy: 0.4999\n",
      "Epoch 207/277\n",
      "278/278 - 10s - loss: 0.0789 - accuracy: 0.5194 - val_loss: 0.0810 - val_accuracy: 0.5047\n",
      "Epoch 208/277\n",
      "278/278 - 10s - loss: 0.0786 - accuracy: 0.5216 - val_loss: 0.0815 - val_accuracy: 0.4982\n",
      "Epoch 209/277\n",
      "278/278 - 10s - loss: 0.0786 - accuracy: 0.5230 - val_loss: 0.0809 - val_accuracy: 0.5047\n",
      "Epoch 210/277\n",
      "278/278 - 10s - loss: 0.0784 - accuracy: 0.5252 - val_loss: 0.0811 - val_accuracy: 0.5057\n",
      "Epoch 211/277\n",
      "278/278 - 11s - loss: 0.0784 - accuracy: 0.5245 - val_loss: 0.0810 - val_accuracy: 0.5024\n",
      "Epoch 212/277\n",
      "278/278 - 10s - loss: 0.0784 - accuracy: 0.5245 - val_loss: 0.0812 - val_accuracy: 0.5027\n",
      "Epoch 213/277\n",
      "278/278 - 10s - loss: 0.0785 - accuracy: 0.5228 - val_loss: 0.0811 - val_accuracy: 0.5022\n",
      "Epoch 214/277\n",
      "278/278 - 10s - loss: 0.0783 - accuracy: 0.5249 - val_loss: 0.0811 - val_accuracy: 0.5031\n",
      "Epoch 215/277\n",
      "278/278 - 10s - loss: 0.0781 - accuracy: 0.5261 - val_loss: 0.0808 - val_accuracy: 0.5064\n",
      "Epoch 216/277\n",
      "278/278 - 10s - loss: 0.0781 - accuracy: 0.5277 - val_loss: 0.0806 - val_accuracy: 0.5074\n",
      "Epoch 217/277\n",
      "278/278 - 10s - loss: 0.0779 - accuracy: 0.5278 - val_loss: 0.0805 - val_accuracy: 0.5100\n",
      "Epoch 218/277\n",
      "278/278 - 10s - loss: 0.0777 - accuracy: 0.5299 - val_loss: 0.0804 - val_accuracy: 0.5076\n",
      "Epoch 219/277\n",
      "278/278 - 10s - loss: 0.0777 - accuracy: 0.5308 - val_loss: 0.0808 - val_accuracy: 0.5097\n",
      "Epoch 220/277\n",
      "278/278 - 10s - loss: 0.0777 - accuracy: 0.5308 - val_loss: 0.0807 - val_accuracy: 0.5083\n",
      "Epoch 221/277\n",
      "278/278 - 10s - loss: 0.0776 - accuracy: 0.5303 - val_loss: 0.0803 - val_accuracy: 0.5091\n",
      "Epoch 222/277\n",
      "278/278 - 10s - loss: 0.0776 - accuracy: 0.5296 - val_loss: 0.0808 - val_accuracy: 0.5025\n",
      "Epoch 223/277\n",
      "278/278 - 10s - loss: 0.0774 - accuracy: 0.5314 - val_loss: 0.0804 - val_accuracy: 0.5123\n",
      "Epoch 224/277\n",
      "278/278 - 10s - loss: 0.0771 - accuracy: 0.5341 - val_loss: 0.0802 - val_accuracy: 0.5112\n",
      "Epoch 225/277\n",
      "278/278 - 10s - loss: 0.0773 - accuracy: 0.5337 - val_loss: 0.0803 - val_accuracy: 0.5099\n",
      "Epoch 226/277\n",
      "278/278 - 10s - loss: 0.0768 - accuracy: 0.5366 - val_loss: 0.0799 - val_accuracy: 0.5150\n",
      "Epoch 227/277\n",
      "278/278 - 10s - loss: 0.0769 - accuracy: 0.5371 - val_loss: 0.0800 - val_accuracy: 0.5116\n",
      "Epoch 228/277\n",
      "278/278 - 10s - loss: 0.0769 - accuracy: 0.5367 - val_loss: 0.0797 - val_accuracy: 0.5133\n",
      "Epoch 229/277\n",
      "278/278 - 9s - loss: 0.0769 - accuracy: 0.5354 - val_loss: 0.0801 - val_accuracy: 0.5136\n",
      "Epoch 230/277\n",
      "278/278 - 10s - loss: 0.0768 - accuracy: 0.5369 - val_loss: 0.0796 - val_accuracy: 0.5149\n",
      "Epoch 231/277\n",
      "278/278 - 10s - loss: 0.0765 - accuracy: 0.5379 - val_loss: 0.0799 - val_accuracy: 0.5146\n",
      "Epoch 232/277\n",
      "278/278 - 10s - loss: 0.0766 - accuracy: 0.5393 - val_loss: 0.0800 - val_accuracy: 0.5145\n",
      "Epoch 233/277\n",
      "278/278 - 10s - loss: 0.0763 - accuracy: 0.5398 - val_loss: 0.0797 - val_accuracy: 0.5166\n",
      "Epoch 234/277\n",
      "278/278 - 10s - loss: 0.0765 - accuracy: 0.5381 - val_loss: 0.0796 - val_accuracy: 0.5204\n",
      "Epoch 235/277\n",
      "278/278 - 10s - loss: 0.0762 - accuracy: 0.5402 - val_loss: 0.0796 - val_accuracy: 0.5188\n",
      "Epoch 236/277\n",
      "278/278 - 11s - loss: 0.0762 - accuracy: 0.5419 - val_loss: 0.0794 - val_accuracy: 0.5198\n",
      "Epoch 237/277\n",
      "278/278 - 11s - loss: 0.0762 - accuracy: 0.5417 - val_loss: 0.0794 - val_accuracy: 0.5166\n",
      "Epoch 238/277\n",
      "278/278 - 10s - loss: 0.0761 - accuracy: 0.5428 - val_loss: 0.0796 - val_accuracy: 0.5178\n",
      "Epoch 239/277\n",
      "278/278 - 10s - loss: 0.0760 - accuracy: 0.5426 - val_loss: 0.0796 - val_accuracy: 0.5148\n",
      "Epoch 240/277\n",
      "278/278 - 10s - loss: 0.0758 - accuracy: 0.5449 - val_loss: 0.0793 - val_accuracy: 0.5198\n",
      "Epoch 241/277\n",
      "278/278 - 10s - loss: 0.0757 - accuracy: 0.5457 - val_loss: 0.0793 - val_accuracy: 0.5181\n",
      "Epoch 242/277\n",
      "278/278 - 10s - loss: 0.0759 - accuracy: 0.5432 - val_loss: 0.0790 - val_accuracy: 0.5221\n",
      "Epoch 243/277\n",
      "278/278 - 11s - loss: 0.0756 - accuracy: 0.5446 - val_loss: 0.0791 - val_accuracy: 0.5228\n",
      "Epoch 244/277\n",
      "278/278 - 10s - loss: 0.0753 - accuracy: 0.5489 - val_loss: 0.0794 - val_accuracy: 0.5183\n",
      "Epoch 245/277\n",
      "278/278 - 10s - loss: 0.0755 - accuracy: 0.5465 - val_loss: 0.0792 - val_accuracy: 0.5212\n",
      "Epoch 246/277\n",
      "278/278 - 10s - loss: 0.0754 - accuracy: 0.5496 - val_loss: 0.0791 - val_accuracy: 0.5227\n",
      "Epoch 247/277\n",
      "278/278 - 10s - loss: 0.0752 - accuracy: 0.5480 - val_loss: 0.0792 - val_accuracy: 0.5201\n",
      "Epoch 248/277\n",
      "278/278 - 10s - loss: 0.0751 - accuracy: 0.5500 - val_loss: 0.0787 - val_accuracy: 0.5242\n",
      "Epoch 249/277\n",
      "278/278 - 10s - loss: 0.0751 - accuracy: 0.5505 - val_loss: 0.0790 - val_accuracy: 0.5221\n",
      "Epoch 250/277\n",
      "278/278 - 10s - loss: 0.0750 - accuracy: 0.5486 - val_loss: 0.0785 - val_accuracy: 0.5250\n",
      "Epoch 251/277\n",
      "278/278 - 11s - loss: 0.0749 - accuracy: 0.5513 - val_loss: 0.0787 - val_accuracy: 0.5267\n",
      "Epoch 252/277\n",
      "278/278 - 10s - loss: 0.0749 - accuracy: 0.5524 - val_loss: 0.0787 - val_accuracy: 0.5227\n",
      "Epoch 253/277\n",
      "278/278 - 10s - loss: 0.0746 - accuracy: 0.5528 - val_loss: 0.0785 - val_accuracy: 0.5281\n",
      "Epoch 254/277\n",
      "278/278 - 10s - loss: 0.0749 - accuracy: 0.5500 - val_loss: 0.0785 - val_accuracy: 0.5228\n",
      "Epoch 255/277\n",
      "278/278 - 10s - loss: 0.0745 - accuracy: 0.5536 - val_loss: 0.0788 - val_accuracy: 0.5257\n",
      "Epoch 256/277\n",
      "278/278 - 10s - loss: 0.0744 - accuracy: 0.5546 - val_loss: 0.0788 - val_accuracy: 0.5237\n",
      "Epoch 257/277\n",
      "278/278 - 10s - loss: 0.0744 - accuracy: 0.5561 - val_loss: 0.0789 - val_accuracy: 0.5204\n",
      "Epoch 258/277\n",
      "278/278 - 10s - loss: 0.0743 - accuracy: 0.5552 - val_loss: 0.0786 - val_accuracy: 0.5266\n",
      "Epoch 259/277\n",
      "278/278 - 10s - loss: 0.0741 - accuracy: 0.5578 - val_loss: 0.0786 - val_accuracy: 0.5251\n",
      "Epoch 260/277\n",
      "278/278 - 10s - loss: 0.0741 - accuracy: 0.5560 - val_loss: 0.0780 - val_accuracy: 0.5300\n",
      "Epoch 261/277\n",
      "278/278 - 10s - loss: 0.0740 - accuracy: 0.5582 - val_loss: 0.0784 - val_accuracy: 0.5276\n",
      "Epoch 262/277\n",
      "278/278 - 10s - loss: 0.0739 - accuracy: 0.5585 - val_loss: 0.0784 - val_accuracy: 0.5277\n",
      "Epoch 263/277\n",
      "278/278 - 11s - loss: 0.0740 - accuracy: 0.5579 - val_loss: 0.0781 - val_accuracy: 0.5287\n",
      "Epoch 264/277\n",
      "278/278 - 10s - loss: 0.0739 - accuracy: 0.5576 - val_loss: 0.0788 - val_accuracy: 0.5222\n",
      "Epoch 265/277\n",
      "278/278 - 10s - loss: 0.0738 - accuracy: 0.5591 - val_loss: 0.0780 - val_accuracy: 0.5306\n",
      "Epoch 266/277\n",
      "278/278 - 10s - loss: 0.0737 - accuracy: 0.5597 - val_loss: 0.0781 - val_accuracy: 0.5281\n",
      "Epoch 267/277\n",
      "278/278 - 11s - loss: 0.0737 - accuracy: 0.5614 - val_loss: 0.0780 - val_accuracy: 0.5307\n",
      "Epoch 268/277\n",
      "278/278 - 10s - loss: 0.0736 - accuracy: 0.5614 - val_loss: 0.0778 - val_accuracy: 0.5312\n",
      "Epoch 269/277\n",
      "278/278 - 10s - loss: 0.0735 - accuracy: 0.5598 - val_loss: 0.0777 - val_accuracy: 0.5314\n",
      "Epoch 270/277\n",
      "278/278 - 10s - loss: 0.0732 - accuracy: 0.5644 - val_loss: 0.0777 - val_accuracy: 0.5340\n",
      "Epoch 271/277\n",
      "278/278 - 10s - loss: 0.0734 - accuracy: 0.5613 - val_loss: 0.0776 - val_accuracy: 0.5359\n",
      "Epoch 272/277\n",
      "278/278 - 10s - loss: 0.0732 - accuracy: 0.5642 - val_loss: 0.0779 - val_accuracy: 0.5348\n",
      "Epoch 273/277\n",
      "278/278 - 10s - loss: 0.0729 - accuracy: 0.5662 - val_loss: 0.0778 - val_accuracy: 0.5309\n",
      "Epoch 274/277\n",
      "278/278 - 10s - loss: 0.0731 - accuracy: 0.5629 - val_loss: 0.0775 - val_accuracy: 0.5372\n",
      "Epoch 275/277\n",
      "278/278 - 10s - loss: 0.0728 - accuracy: 0.5675 - val_loss: 0.0775 - val_accuracy: 0.5339\n",
      "Epoch 276/277\n",
      "278/278 - 10s - loss: 0.0730 - accuracy: 0.5654 - val_loss: 0.0780 - val_accuracy: 0.5267\n",
      "Epoch 277/277\n",
      "278/278 - 10s - loss: 0.0727 - accuracy: 0.5690 - val_loss: 0.0771 - val_accuracy: 0.5386\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val,), batch_size=best_params['batch_size'], epochs=int(X_train.shape[0]/best_params['batch_size']), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER     0.5104    0.5069    0.5086      1016\n",
      "    CONTEMPT     0.5462    0.5717    0.5587       899\n",
      "     DISGUST     0.5577    0.5494    0.5535      1003\n",
      "        FEAR     0.5205    0.4800    0.4995       977\n",
      "   HAPPINESS     0.6345    0.7088    0.6696       982\n",
      "     NEUTRAL     0.4781    0.4598    0.4688       996\n",
      "     SADNESS     0.5164    0.4885    0.5021      1001\n",
      "    SURPRISE     0.6273    0.6517    0.6393       847\n",
      "\n",
      "    accuracy                         0.5497      7721\n",
      "   macro avg     0.5489    0.5521    0.5500      7721\n",
      "weighted avg     0.5472    0.5497    0.5479      7721\n",
      "\n",
      "(7721, 8) (7721,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7360/4490163.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ANGER'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CONTEMPT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DISGUST'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'FEAR'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'HAPPINESS'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;34m'NEUTRAL'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SADNESS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SURPRISE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdisp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \"\"\"\n\u001b[1;32m--> 307\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "dictionary = {0: 'ANGER', 1: 'CONTEMPT', 2: 'DISGUST', 3: 'FEAR', 4: 'HAPPINESS',  5: 'NEUTRAL', 6: 'SADNESS', 7: 'SURPRISE'}\n",
    "target_name = [dictionary[i] for i in range(len(dictionary))]\n",
    "\n",
    "value = model.predict(X_test)\n",
    "y_pred = np.argmax(value, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "print(classification_report(y_true,y_pred, target_names=target_name, digits=4))\n",
    "\n",
    "print(y_test.shape, y_true.shape)\n",
    "\n",
    "dictionary = ['ANGER', 'CONTEMPT', 'DISGUST', 'FEAR', 'HAPPINESS',  'NEUTRAL', 'SADNESS', 'SURPRISE']\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dictionary)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "disp.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGER\n",
      "Epoch 1/210\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7360/77277320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model_best_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         model.fit(X_train_kf,\n\u001b[0m\u001b[0;32m     37\u001b[0m                     \u001b[0my_train_kf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[1;31m# validation_data=(X_val_kf, y_val_kf,),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "dictionary = ['ANGER', 'CONTEMPT', 'DISGUST', 'FEAR', 'HAPPINESS',  'NEUTRAL', 'SADNESS', 'SURPRISE']\n",
    "\n",
    "for idx in range(len(dictionary)):\n",
    "    print(dictionary[idx])\n",
    "\n",
    "    emo_feature = np.copy(X_train)\n",
    "    emo_target = list(label[idx] for label in y_train)\n",
    "    emo_target = np.array(emo_target)\n",
    "\n",
    "    X = emo_feature\n",
    "    y = emo_target\n",
    "\n",
    "    history = []\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # plot ROC curves\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for i, (train, val) in enumerate(cv.split(X, y)):\n",
    "        X_train_kf, X_val_kf = X[train], X[val]\n",
    "        y_train_kf, y_val_kf = y[train], y[val]\n",
    "\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        y_train_kf = to_categorical(y_train_kf)\n",
    "        y_val_kf = to_categorical(y_val_kf)\n",
    "\n",
    "        model = create_model_best_param(best_params, 2)\n",
    "        model.fit(X_train_kf,\n",
    "                    y_train_kf,\n",
    "                    # validation_data=(X_val_kf, y_val_kf,),\n",
    "                    batch_size=best_params['batch_size'],\n",
    "                    epochs=best_params[\"epochs\"],\n",
    "                    verbose=2)\n",
    "\n",
    "        # predict\n",
    "        y_pred = model.predict(X_val_kf).ravel()\n",
    "        y_val_kf = y_val_kf.ravel()\n",
    "\n",
    "        print('====================Fold ', i , '====================')\n",
    "\n",
    "        # plot ROC curve\n",
    "        viz = RocCurveDisplay.from_predictions(y_val_kf, y_pred, ax=ax, name=\"ROC fold {}\".format(i), alpha=0.3, lw=1,)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "    # middle line\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    # mean line\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    # std\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "    ax.set(xlim=[-0.05, 1.05],\n",
    "            ylim=[-0.05, 1.05],\n",
    "            title=\"Receiver operating characteristic\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.savefig(cwd + '/../graph/' + dictionary[idx] + '/ann_relu.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278/278 - 12s - loss: 0.1318 - accuracy: 0.1343 - val_loss: 0.1207 - val_accuracy: 0.1574\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7360/2135313426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mnn_fpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_tpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_thresholds_keras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mauc_keras\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_fpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_tpr_keras\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn_fpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnn_tpr_keras\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Neural Network (auc = %0.3f)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mauc_keras\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m     \"\"\"\n\u001b[1;32m--> 962\u001b[1;33m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[0;32m    963\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m     )\n",
      "\u001b[1;32md:\\DownloadApplication\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multilabel-indicator format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "dictionary = ['ANGER', 'CONTEMPT', 'DISGUST', 'FEAR', 'HAPPINESS',  'NEUTRAL', 'SADNESS', 'SURPRISE']\n",
    "\n",
    "model = create_model_best_param(best_params, 8)\n",
    "model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val,), \n",
    "                    batch_size=best_params['batch_size'], \n",
    "                    epochs=1, #int(X_train.shape[0]/best_params['batch_size']), \n",
    "                    verbose=2)\n",
    "\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "\n",
    "nn_fpr_keras, nn_tpr_keras, nn_thresholds_keras = roc_curve(y_test, y_pred)\n",
    "auc_keras = auc(nn_fpr_keras, nn_tpr_keras)\n",
    "plt.plot(nn_fpr_keras, nn_tpr_keras, marker='.', label='Neural Network (auc = %0.3f)' % auc_keras)\n",
    "\n",
    "\n",
    "'''\n",
    "model = create_model_best_param(best_params, 8)\n",
    "model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val,), \n",
    "                    batch_size=best_params['batch_size'], \n",
    "                    epochs=int(X_train.shape[0]/best_params['batch_size']), \n",
    "                    verbose=2)\n",
    "y_score = model.decision_function(X_test)\n",
    "\n",
    "# ROC curve for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(dictionary)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# plot ROC curve\n",
    "plt.figure()\n",
    "for i in range(len(dictionary)):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {} (area = {1:0.2f})'.format(dictionary[i], roc_auc[i]))\n",
    "\n",
    "# middle line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# mean line\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"Receiver operating characteristic (multi-class)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(cwd + '/../graph/ann_relu_allemotion.jpg')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'model_relu_best'\n",
    "path = cwd + \"/model/\" + name\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.makedirs(path)\n",
    "\n",
    "model.save(path)\n",
    "# model = keras.models.load_model(path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "efc329eb76fa8c61d98fc33828834e5a32dbc6c00e0ecf46855e3ac0d7163765"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
