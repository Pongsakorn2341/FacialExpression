{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import f1_score ,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, imutils\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "    [0, 180, 0, 256, 0, 256])\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist)\n",
    "    else:\n",
    "        cv2.normalize(hist, hist)\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pongsakorn\\OneDrive\\Desktop\\Working\\FacialLandMarks\\facial_cleandata\\neural_network\n",
      "                                 image   emotion\n",
      "0      facial-expressions_2868588k.jpg     anger\n",
      "1      facial-expressions_2868585k.jpg  surprise\n",
      "2      facial-expressions_2868584k.jpg   disgust\n",
      "3      facial-expressions_2868582k.jpg      fear\n",
      "4               Aaron_Eckhart_0001.jpg   neutral\n",
      "...                                ...       ...\n",
      "34670      SURPRISE/surprise (988).jpg  SURPRISE\n",
      "34671       SURPRISE/surprise (99).jpg  SURPRISE\n",
      "34672      SURPRISE/surprise (993).jpg  SURPRISE\n",
      "34673      SURPRISE/surprise (994).png  SURPRISE\n",
      "34674      SURPRISE/surprise (996).jpg  SURPRISE\n",
      "\n",
      "[34675 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "df = pd.read_csv(cwd + \"\\\\..\\\\data_csv\\\\all_data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000/34675\n",
      "[INFO] processed 2000/34675\n",
      "[INFO] processed 3000/34675\n",
      "[INFO] processed 4000/34675\n",
      "[INFO] processed 5000/34675\n",
      "[INFO] processed 6000/34675\n",
      "[INFO] processed 7000/34675\n",
      "[INFO] processed 8000/34675\n",
      "[INFO] processed 9000/34675\n",
      "[INFO] processed 10000/34675\n",
      "[INFO] processed 11000/34675\n",
      "[INFO] processed 12000/34675\n",
      "[INFO] processed 13000/34675\n",
      "[INFO] processed 14000/34675\n",
      "[INFO] processed 15000/34675\n",
      "[INFO] processed 16000/34675\n",
      "[INFO] processed 17000/34675\n",
      "[INFO] processed 18000/34675\n",
      "[INFO] processed 19000/34675\n",
      "[INFO] processed 20000/34675\n",
      "[INFO] processed 21000/34675\n",
      "[INFO] processed 22000/34675\n",
      "[INFO] processed 23000/34675\n",
      "[INFO] processed 24000/34675\n",
      "[INFO] processed 25000/34675\n",
      "[INFO] processed 26000/34675\n",
      "[INFO] processed 27000/34675\n",
      "[INFO] processed 28000/34675\n",
      "[INFO] processed 29000/34675\n",
      "[INFO] processed 30000/34675\n",
      "[INFO] processed 31000/34675\n",
      "[INFO] processed 32000/34675\n",
      "[INFO] processed 33000/34675\n",
      "[INFO] processed 34000/34675\n"
     ]
    }
   ],
   "source": [
    "raw_images =  []\n",
    "labels = []\n",
    "for i, row in df.iterrows():\n",
    "    image_path = row['image']\n",
    "    label = row['emotion']\n",
    "    full_image_path = os.path.dirname(cwd) + \"\\\\cleaned_images\\\\\" + image_path\n",
    "    image = cv2.imread(full_image_path)\n",
    "    pixels = extract_color_histogram(image)\n",
    "\n",
    "    raw_images.append(pixels)\n",
    "    labels.append(label)\n",
    "    if i > 0 and i % 1000 == 0: print('[INFO] processed {}/{}'.format(i, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(raw_images), np.array(labels), random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "y_val = le.transform(y_val)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def classification_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(124, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(124, activation='relu'))\n",
    "    # model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 - 2s - loss: 2.5518 - accuracy: 0.1338 - val_loss: 2.3365 - val_accuracy: 0.1195 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "610/610 - 1s - loss: 2.3193 - accuracy: 0.1549 - val_loss: 2.2985 - val_accuracy: 0.1769 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "610/610 - 1s - loss: 2.2905 - accuracy: 0.1748 - val_loss: 2.2610 - val_accuracy: 0.1949 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "610/610 - 1s - loss: 2.2603 - accuracy: 0.1837 - val_loss: 2.2362 - val_accuracy: 0.2024 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "610/610 - 1s - loss: 2.2405 - accuracy: 0.1921 - val_loss: 2.2219 - val_accuracy: 0.1982 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "610/610 - 1s - loss: 2.2313 - accuracy: 0.1893 - val_loss: 2.2146 - val_accuracy: 0.2032 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "610/610 - 1s - loss: 2.2212 - accuracy: 0.1971 - val_loss: 2.2096 - val_accuracy: 0.2058 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "610/610 - 1s - loss: 2.2178 - accuracy: 0.1942 - val_loss: 2.2082 - val_accuracy: 0.2044 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "610/610 - 1s - loss: 2.2126 - accuracy: 0.1936 - val_loss: 2.2042 - val_accuracy: 0.2038 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "610/610 - 1s - loss: 2.2111 - accuracy: 0.1967 - val_loss: 2.2031 - val_accuracy: 0.2081 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "610/610 - 1s - loss: 2.2083 - accuracy: 0.1968 - val_loss: 2.2023 - val_accuracy: 0.2062 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "610/610 - 1s - loss: 2.2063 - accuracy: 0.1960 - val_loss: 2.1997 - val_accuracy: 0.2093 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "610/610 - 1s - loss: 2.2037 - accuracy: 0.1937 - val_loss: 2.2000 - val_accuracy: 0.2033 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "610/610 - 1s - loss: 2.2035 - accuracy: 0.1954 - val_loss: 2.1977 - val_accuracy: 0.2086 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "610/610 - 1s - loss: 2.2028 - accuracy: 0.1958 - val_loss: 2.1965 - val_accuracy: 0.2073 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "610/610 - 1s - loss: 2.1986 - accuracy: 0.1972 - val_loss: 2.1966 - val_accuracy: 0.2087 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "610/610 - 1s - loss: 2.1991 - accuracy: 0.1959 - val_loss: 2.1951 - val_accuracy: 0.2059 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "610/610 - 1s - loss: 2.1983 - accuracy: 0.1986 - val_loss: 2.1972 - val_accuracy: 0.2101 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "610/610 - 1s - loss: 2.1971 - accuracy: 0.2032 - val_loss: 2.1933 - val_accuracy: 0.2076 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "610/610 - 1s - loss: 2.1967 - accuracy: 0.1975 - val_loss: 2.1920 - val_accuracy: 0.2069 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "610/610 - 1s - loss: 2.1928 - accuracy: 0.1990 - val_loss: 2.1924 - val_accuracy: 0.2112 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "610/610 - 1s - loss: 2.1945 - accuracy: 0.1981 - val_loss: 2.1904 - val_accuracy: 0.2081 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "610/610 - 1s - loss: 2.1903 - accuracy: 0.2021 - val_loss: 2.1907 - val_accuracy: 0.2058 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "610/610 - 1s - loss: 2.1919 - accuracy: 0.2026 - val_loss: 2.1887 - val_accuracy: 0.2107 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "610/610 - 1s - loss: 2.1910 - accuracy: 0.2011 - val_loss: 2.1880 - val_accuracy: 0.2089 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "610/610 - 1s - loss: 2.1900 - accuracy: 0.2017 - val_loss: 2.1862 - val_accuracy: 0.2125 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "610/610 - 1s - loss: 2.1884 - accuracy: 0.2049 - val_loss: 2.1856 - val_accuracy: 0.2116 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "610/610 - 1s - loss: 2.1867 - accuracy: 0.2002 - val_loss: 2.1884 - val_accuracy: 0.2122 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "610/610 - 1s - loss: 2.1861 - accuracy: 0.2066 - val_loss: 2.1846 - val_accuracy: 0.2153 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "610/610 - 1s - loss: 2.1839 - accuracy: 0.2057 - val_loss: 2.1824 - val_accuracy: 0.2072 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "610/610 - 1s - loss: 2.1837 - accuracy: 0.2074 - val_loss: 2.1823 - val_accuracy: 0.2155 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "610/610 - 1s - loss: 2.1843 - accuracy: 0.2050 - val_loss: 2.1812 - val_accuracy: 0.2132 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "610/610 - 1s - loss: 2.1824 - accuracy: 0.2058 - val_loss: 2.1815 - val_accuracy: 0.2086 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "610/610 - 1s - loss: 2.1825 - accuracy: 0.2057 - val_loss: 2.1805 - val_accuracy: 0.2116 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "610/610 - 1s - loss: 2.1785 - accuracy: 0.2079 - val_loss: 2.1791 - val_accuracy: 0.2106 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "610/610 - 1s - loss: 2.1777 - accuracy: 0.2089 - val_loss: 2.1786 - val_accuracy: 0.2115 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "610/610 - 1s - loss: 2.1796 - accuracy: 0.2058 - val_loss: 2.1801 - val_accuracy: 0.2147 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "610/610 - 1s - loss: 2.1792 - accuracy: 0.2093 - val_loss: 2.1786 - val_accuracy: 0.2125 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "610/610 - 1s - loss: 2.1755 - accuracy: 0.2111 - val_loss: 2.1762 - val_accuracy: 0.2116 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "610/610 - 1s - loss: 2.1770 - accuracy: 0.2109 - val_loss: 2.1769 - val_accuracy: 0.2122 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "610/610 - 1s - loss: 2.1760 - accuracy: 0.2090 - val_loss: 2.1754 - val_accuracy: 0.2142 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "610/610 - 1s - loss: 2.1757 - accuracy: 0.2086 - val_loss: 2.1752 - val_accuracy: 0.2133 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "610/610 - 1s - loss: 2.1739 - accuracy: 0.2101 - val_loss: 2.1745 - val_accuracy: 0.2118 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "610/610 - 1s - loss: 2.1732 - accuracy: 0.2124 - val_loss: 2.1734 - val_accuracy: 0.2144 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "610/610 - 1s - loss: 2.1747 - accuracy: 0.2072 - val_loss: 2.1733 - val_accuracy: 0.2136 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "610/610 - 1s - loss: 2.1721 - accuracy: 0.2086 - val_loss: 2.1729 - val_accuracy: 0.2132 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "610/610 - 1s - loss: 2.1720 - accuracy: 0.2108 - val_loss: 2.1726 - val_accuracy: 0.2149 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "610/610 - 1s - loss: 2.1717 - accuracy: 0.2102 - val_loss: 2.1711 - val_accuracy: 0.2124 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "610/610 - 1s - loss: 2.1712 - accuracy: 0.2124 - val_loss: 2.1721 - val_accuracy: 0.2139 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "610/610 - 1s - loss: 2.1698 - accuracy: 0.2069 - val_loss: 2.1727 - val_accuracy: 0.2156 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "610/610 - 1s - loss: 2.1687 - accuracy: 0.2108 - val_loss: 2.1700 - val_accuracy: 0.2149 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "610/610 - 1s - loss: 2.1689 - accuracy: 0.2098 - val_loss: 2.1694 - val_accuracy: 0.2122 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "610/610 - 1s - loss: 2.1682 - accuracy: 0.2120 - val_loss: 2.1701 - val_accuracy: 0.2152 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "610/610 - 1s - loss: 2.1679 - accuracy: 0.2125 - val_loss: 2.1683 - val_accuracy: 0.2142 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "610/610 - 1s - loss: 2.1669 - accuracy: 0.2158 - val_loss: 2.1687 - val_accuracy: 0.2167 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "610/610 - 1s - loss: 2.1658 - accuracy: 0.2111 - val_loss: 2.1687 - val_accuracy: 0.2147 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "610/610 - 1s - loss: 2.1666 - accuracy: 0.2131 - val_loss: 2.1670 - val_accuracy: 0.2145 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "610/610 - 1s - loss: 2.1659 - accuracy: 0.2156 - val_loss: 2.1678 - val_accuracy: 0.2170 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "610/610 - 1s - loss: 2.1635 - accuracy: 0.2121 - val_loss: 2.1665 - val_accuracy: 0.2144 - 1s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "610/610 - 1s - loss: 2.1642 - accuracy: 0.2150 - val_loss: 2.1658 - val_accuracy: 0.2125 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "610/610 - 1s - loss: 2.1637 - accuracy: 0.2152 - val_loss: 2.1649 - val_accuracy: 0.2152 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "610/610 - 1s - loss: 2.1627 - accuracy: 0.2138 - val_loss: 2.1651 - val_accuracy: 0.2144 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "610/610 - 1s - loss: 2.1629 - accuracy: 0.2134 - val_loss: 2.1651 - val_accuracy: 0.2162 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "610/610 - 1s - loss: 2.1628 - accuracy: 0.2125 - val_loss: 2.1662 - val_accuracy: 0.2165 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "610/610 - 1s - loss: 2.1630 - accuracy: 0.2122 - val_loss: 2.1642 - val_accuracy: 0.2162 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "610/610 - 1s - loss: 2.1608 - accuracy: 0.2136 - val_loss: 2.1642 - val_accuracy: 0.2147 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "610/610 - 1s - loss: 2.1606 - accuracy: 0.2140 - val_loss: 2.1625 - val_accuracy: 0.2135 - 1s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "610/610 - 1s - loss: 2.1600 - accuracy: 0.2142 - val_loss: 2.1624 - val_accuracy: 0.2130 - 1s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "610/610 - 1s - loss: 2.1611 - accuracy: 0.2167 - val_loss: 2.1629 - val_accuracy: 0.2173 - 1s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "610/610 - 1s - loss: 2.1584 - accuracy: 0.2147 - val_loss: 2.1625 - val_accuracy: 0.2172 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "610/610 - 1s - loss: 2.1581 - accuracy: 0.2160 - val_loss: 2.1632 - val_accuracy: 0.2155 - 1s/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "610/610 - 1s - loss: 2.1594 - accuracy: 0.2160 - val_loss: 2.1617 - val_accuracy: 0.2142 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "610/610 - 1s - loss: 2.1568 - accuracy: 0.2134 - val_loss: 2.1609 - val_accuracy: 0.2158 - 1s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "610/610 - 1s - loss: 2.1577 - accuracy: 0.2137 - val_loss: 2.1609 - val_accuracy: 0.2141 - 1s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "610/610 - 1s - loss: 2.1562 - accuracy: 0.2148 - val_loss: 2.1606 - val_accuracy: 0.2153 - 1s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "610/610 - 1s - loss: 2.1583 - accuracy: 0.2160 - val_loss: 2.1596 - val_accuracy: 0.2152 - 1s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "610/610 - 1s - loss: 2.1574 - accuracy: 0.2161 - val_loss: 2.1601 - val_accuracy: 0.2175 - 1s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "610/610 - 1s - loss: 2.1563 - accuracy: 0.2127 - val_loss: 2.1605 - val_accuracy: 0.2181 - 1s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "610/610 - 1s - loss: 2.1543 - accuracy: 0.2168 - val_loss: 2.1596 - val_accuracy: 0.2165 - 1s/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "610/610 - 1s - loss: 2.1553 - accuracy: 0.2132 - val_loss: 2.1579 - val_accuracy: 0.2169 - 1s/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "610/610 - 1s - loss: 2.1546 - accuracy: 0.2187 - val_loss: 2.1590 - val_accuracy: 0.2169 - 1s/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "610/610 - 1s - loss: 2.1562 - accuracy: 0.2154 - val_loss: 2.1576 - val_accuracy: 0.2179 - 1s/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "610/610 - 1s - loss: 2.1541 - accuracy: 0.2156 - val_loss: 2.1581 - val_accuracy: 0.2209 - 1s/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "610/610 - 1s - loss: 2.1535 - accuracy: 0.2171 - val_loss: 2.1579 - val_accuracy: 0.2179 - 1s/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "610/610 - 1s - loss: 2.1542 - accuracy: 0.2167 - val_loss: 2.1579 - val_accuracy: 0.2192 - 1s/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "610/610 - 1s - loss: 2.1540 - accuracy: 0.2171 - val_loss: 2.1559 - val_accuracy: 0.2187 - 1s/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "610/610 - 1s - loss: 2.1539 - accuracy: 0.2174 - val_loss: 2.1569 - val_accuracy: 0.2202 - 1s/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "610/610 - 1s - loss: 2.1506 - accuracy: 0.2166 - val_loss: 2.1611 - val_accuracy: 0.2198 - 1s/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "610/610 - 1s - loss: 2.1523 - accuracy: 0.2188 - val_loss: 2.1573 - val_accuracy: 0.2187 - 1s/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "610/610 - 1s - loss: 2.1520 - accuracy: 0.2173 - val_loss: 2.1587 - val_accuracy: 0.2172 - 1s/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "610/610 - 1s - loss: 2.1505 - accuracy: 0.2185 - val_loss: 2.1567 - val_accuracy: 0.2184 - 1s/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "610/610 - 1s - loss: 2.1514 - accuracy: 0.2163 - val_loss: 2.1563 - val_accuracy: 0.2198 - 1s/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "610/610 - 1s - loss: 2.1504 - accuracy: 0.2171 - val_loss: 2.1551 - val_accuracy: 0.2196 - 1s/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "610/610 - 1s - loss: 2.1493 - accuracy: 0.2196 - val_loss: 2.1542 - val_accuracy: 0.2179 - 1s/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "610/610 - 1s - loss: 2.1487 - accuracy: 0.2183 - val_loss: 2.1539 - val_accuracy: 0.2207 - 1s/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "610/610 - 1s - loss: 2.1478 - accuracy: 0.2192 - val_loss: 2.1551 - val_accuracy: 0.2207 - 1s/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "610/610 - 1s - loss: 2.1478 - accuracy: 0.2202 - val_loss: 2.1537 - val_accuracy: 0.2185 - 1s/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "610/610 - 1s - loss: 2.1485 - accuracy: 0.2186 - val_loss: 2.1546 - val_accuracy: 0.2213 - 1s/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "610/610 - 1s - loss: 2.1487 - accuracy: 0.2182 - val_loss: 2.1540 - val_accuracy: 0.2201 - 1s/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "610/610 - 1s - loss: 2.1479 - accuracy: 0.2198 - val_loss: 2.1542 - val_accuracy: 0.2199 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x290bbc4d1f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = classification_model()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val,), epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model.predict(X_test)\n",
    "y_pred =np.argmax(value,axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       579\n",
      "           1       0.00      0.00      0.00       536\n",
      "           2       0.00      0.00      0.00       636\n",
      "           3       0.12      0.01      0.02       641\n",
      "           4       0.18      0.05      0.08      1120\n",
      "           5       0.17      0.50      0.25      1164\n",
      "           6       0.00      0.00      0.00       741\n",
      "           7       0.23      0.12      0.16       803\n",
      "           8       0.00      0.00      0.00        46\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.00      0.00      0.00      1066\n",
      "          13       0.22      0.80      0.35      1249\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.20      8669\n",
      "   macro avg       0.06      0.09      0.05      8669\n",
      "weighted avg       0.11      0.20      0.11      8669\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model.predict(X_test)\n",
    "y_pred = np.argmax(value,axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len :  8669\n",
      "Final Score : 1739/8669\n",
      "Accuracy :  20.059983850501787\n"
     ]
    }
   ],
   "source": [
    "y_pred_arr = list(y_pred)\n",
    "print(\"len : \", len(y_pred_arr))\n",
    "score = 0\n",
    "for i in range(len(y_pred_arr)):\n",
    "    if(list(y_pred)[i] == list(y_true)[i]): score += 1\n",
    "max_score = len(list(y_pred))\n",
    "print(f\"Final Score : {score}/{max_score}\")\n",
    "print(\"Accuracy : \", 100 * score / max_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Process #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "# Parameters and time for FOPDT model\n",
    "ns = 10000\n",
    "t = np.linspace(0,ns-1,ns)\n",
    "u = np.zeros(ns)\n",
    "# Additional FOPDT parameters\n",
    "yp0 = 0.0\n",
    "u0 = u[0]\n",
    "Km = 0.67\n",
    "taum = 160.0\n",
    "def fopdt(y,t,um,Km,taum):\n",
    "    # arguments\n",
    "    #  y      = output\n",
    "    #  t      = time\n",
    "    #  uf     = input linear function (for time shift)\n",
    "    #  Km     = model gain\n",
    "    #  taum   = model time constant\n",
    "    # calculate derivative\n",
    "    dydt = (-(y-yp0) + Km * (um-u0))/taum\n",
    "    return dydt\n",
    "\n",
    "def sim_model(Km,taum):\n",
    "    # array for model values\n",
    "    ym = np.zeros(ns)\n",
    "    # initial condition\n",
    "    ym[0] = yp0\n",
    "    # loop through time steps    \n",
    "    for i in range(0,ns-1):\n",
    "        ts = [t[i],t[i+1]]\n",
    "        y1 = odeint(fopdt,ym[i],ts,args=(u[i],Km,taum))\n",
    "        ym[i+1] = y1[-1]\n",
    "    return ym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "end = 60 # leave 1st minute of u as 0\n",
    "while end <= ns:\n",
    "    start = end\n",
    "    end += random.randint(300,900) # keep new Q1s value for anywhere from 5 to 15 minutes\n",
    "    u[start:end] = random.randint(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate FOPDT model\n",
    "y = sim_model(Km,taum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian noise\n",
    "noise = np.random.normal(0,0.2,ns)\n",
    "y += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Scale data\n",
    "data = np.vstack((u,y)).T\n",
    "s = MinMaxScaler(feature_range=(0,1))\n",
    "data_s = s.fit_transform(data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
