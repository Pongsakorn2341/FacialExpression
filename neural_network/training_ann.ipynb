{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import f1_score ,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, imutils\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\n",
    "    [0, 180, 0, 256, 0, 256])\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist)\n",
    "    else:\n",
    "        cv2.normalize(hist, hist)\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\TU\\2564_2\\CN240\\facial\\neural_network\n",
      "                                 image  emotion\n",
      "0      facial-expressions_2868588k.jpg        0\n",
      "1      facial-expressions_2868585k.jpg        7\n",
      "2      facial-expressions_2868584k.jpg        2\n",
      "3      facial-expressions_2868582k.jpg        3\n",
      "4               Aaron_Eckhart_0001.jpg        5\n",
      "...                                ...      ...\n",
      "33298      SURPRISE/surprise (987).png        7\n",
      "33299      SURPRISE/surprise (988).jpg        7\n",
      "33300       SURPRISE/surprise (99).jpg        7\n",
      "33301      SURPRISE/surprise (993).jpg        7\n",
      "33302      SURPRISE/surprise (996).jpg        7\n",
      "\n",
      "[33303 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "df = pd.read_csv(cwd + \"\\\\..\\\\data_csv\\\\preprocessing_data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 1000/33303\n",
      "[INFO] processed 2000/33303\n",
      "[INFO] processed 3000/33303\n",
      "[INFO] processed 4000/33303\n",
      "[INFO] processed 5000/33303\n",
      "[INFO] processed 6000/33303\n",
      "[INFO] processed 7000/33303\n",
      "[INFO] processed 8000/33303\n",
      "[INFO] processed 9000/33303\n",
      "[INFO] processed 10000/33303\n",
      "[INFO] processed 11000/33303\n",
      "[INFO] processed 12000/33303\n",
      "[INFO] processed 13000/33303\n",
      "[INFO] processed 14000/33303\n",
      "[INFO] processed 15000/33303\n",
      "[INFO] processed 16000/33303\n",
      "[INFO] processed 17000/33303\n",
      "[INFO] processed 18000/33303\n",
      "[INFO] processed 19000/33303\n",
      "[INFO] processed 20000/33303\n",
      "[INFO] processed 21000/33303\n",
      "[INFO] processed 22000/33303\n",
      "[INFO] processed 23000/33303\n",
      "[INFO] processed 24000/33303\n",
      "[INFO] processed 25000/33303\n",
      "[INFO] processed 26000/33303\n",
      "[INFO] processed 27000/33303\n",
      "[INFO] processed 28000/33303\n",
      "[INFO] processed 29000/33303\n",
      "[INFO] processed 30000/33303\n",
      "[INFO] processed 31000/33303\n",
      "[INFO] processed 32000/33303\n",
      "[INFO] processed 33000/33303\n"
     ]
    }
   ],
   "source": [
    "raw_images =  []\n",
    "labels = []\n",
    "for i, row in df.iterrows():\n",
    "    image_path = row['image']\n",
    "    label = row['emotion']\n",
    "    full_image_path = os.path.dirname(cwd) + \"\\\\cleaned_images\\\\\" + image_path\n",
    "    image = cv2.imread(full_image_path)\n",
    "    pixels = extract_color_histogram(image)\n",
    "\n",
    "    raw_images.append(pixels)\n",
    "    labels.append(label)\n",
    "    if i > 0 and i % 1000 == 0: print('[INFO] processed {}/{}'.format(i, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[0.3298029  0.3113486  0.4972276  ... 0.         0.         0.        ]\n",
      " [0.17625485 0.30585727 0.32161003 ... 0.         0.         0.        ]\n",
      " [0.22843178 0.34751016 0.3415906  ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.1783699  0.44123647 0.4242617  ... 0.         0.         0.        ]\n",
      " [0.18133964 0.34290332 0.396603   ... 0.         0.         0.        ]\n",
      " [0.27194506 0.43572003 0.36318737 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(raw_images), np.array(labels), test_size=0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "y_val = le.transform(y_val)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def classification_model_multi():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(124, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(124, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def classification_model_bin():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(124, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(124, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.0001, decay=1e-6)\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x000001FB37DF2F40>\n",
      "ANGER\n",
      "<class 'numpy.ndarray'> [[0.06371864 0.44149336 0.24265932 ... 0.         0.         0.        ]\n",
      " [0.07937567 0.36383924 0.28272468 ... 0.         0.         0.        ]\n",
      " [0.07744719 0.4058253  0.24549863 ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.03373284 0.10399405 0.19480246 ... 0.         0.         0.        ]\n",
      " [0.3770914  0.35567155 0.28794402 ... 0.         0.         0.        ]\n",
      " [0.16595338 0.23644875 0.40159863 ... 0.         0.         0.        ]]\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:245 sigmoid_cross_entropy_with_logits_v2\n        return sigmoid_cross_entropy_with_logits(\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:132 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((None, 8) vs (None, 2))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27580/749063638.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# fit model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m# predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 759\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    760\u001b[0m             *args, **kwds))\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3065\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3066\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3067\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3463\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\training.py:788 train_step\n        loss = self.compiled_loss(\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\engine\\compile_utils.py:201 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\losses.py:141 __call__\n        losses = call_fn(y_true, y_pred)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\losses.py:245 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\losses.py:1809 binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\keras\\backend.py:5000 binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:245 sigmoid_cross_entropy_with_logits_v2\n        return sigmoid_cross_entropy_with_logits(\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\n        return target(*args, **kwargs)\n    D:\\DownloadApplication\\anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:132 sigmoid_cross_entropy_with_logits\n        raise ValueError(\"logits and labels must have the same shape (%s vs %s)\" %\n\n    ValueError: logits and labels must have the same shape ((None, 8) vs (None, 2))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dictionary = ['ANGER', 'CONTEMPT', 'DISGUST', 'FEAR', 'HAPPINESS',  'NEUTRAL', 'SADNESS', 'SURPRISE']\n",
    "\n",
    "for emo in range(8):\n",
    "    print(dictionary[emo])\n",
    "\n",
    "    emo_feature = []\n",
    "    emo_target = []\n",
    "\n",
    "    for i in range(len(df['emotion'])):\n",
    "        if df['emotion'][i] == emo:\n",
    "            emo_target.append(1)\n",
    "        else:\n",
    "            emo_target.append(0)\n",
    "        \n",
    "        imagePath = cwd + \"/../cleaned_images/\" + df['image'][i]\n",
    "        image = cv2.imread(imagePath)\n",
    "        pixels = extract_color_histogram(image)\n",
    "        emo_feature.append(pixels)\n",
    "\n",
    "    emo_feature = np.array(emo_feature)\n",
    "    emo_target = np.array(emo_target)\n",
    "\n",
    "    # import data\n",
    "    X = X_train = emo_feature\n",
    "    y = y_train = emo_target\n",
    "    print(type(X_train), X_train)\n",
    "\n",
    "    history = []\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # create model\n",
    "    model = classification_model_bin()\n",
    "\n",
    "    # Run classifier with cross-validation and plot ROC curves\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for i, (train, val) in enumerate(cv.split(X_train, y_train)):\n",
    "        X_train, X_val = X[train], X[val]\n",
    "        y_train, y_val = y[train], y[val]\n",
    "\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(y_train)\n",
    "        y_train = le.transform(y_train)\n",
    "        y_val = le.transform(y_val)\n",
    "        y_train = to_categorical(y_train)\n",
    "        y_val = to_categorical(y_val)\n",
    "\n",
    "        # fit model\n",
    "        model.fit(X_train, y_train, validation_data=(X_val, y_val,), epochs=100, verbose=2)\n",
    "\n",
    "        # predict\n",
    "        y_pred = model.predict(X_val)\n",
    "        clf_probs = model.predict_proba(X_val)\n",
    "\n",
    "        # store model report in history list\n",
    "        history.append(classification_report(y_val, y_pred))\n",
    "\n",
    "        # get loss and accuracy\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        loss = log_loss(y_val, clf_probs)\n",
    "        print(f'====================Fold {i}====================', '\\n')\n",
    "        print(f\"accuracy_score : {acc}\")\n",
    "        print(f\"log_loss : {loss}\\n\")\n",
    "\n",
    "        # plot ROC curve\n",
    "        viz = RocCurveDisplay.from_predictions(y_val, y_pred)\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "        \n",
    "    # middle line\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "    # mean line\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    # std\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "    ax.set(xlim=[-0.05, 1.05],\n",
    "            ylim=[-0.05, 1.05],\n",
    "            title=\"Receiver operating characteristic\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.savefig('graph/' + dictionary[emo] + '/ann.jpg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 - 2s - loss: 2.5518 - accuracy: 0.1338 - val_loss: 2.3365 - val_accuracy: 0.1195 - 2s/epoch - 3ms/step\n",
      "Epoch 2/100\n",
      "610/610 - 1s - loss: 2.3193 - accuracy: 0.1549 - val_loss: 2.2985 - val_accuracy: 0.1769 - 1s/epoch - 2ms/step\n",
      "Epoch 3/100\n",
      "610/610 - 1s - loss: 2.2905 - accuracy: 0.1748 - val_loss: 2.2610 - val_accuracy: 0.1949 - 1s/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "610/610 - 1s - loss: 2.2603 - accuracy: 0.1837 - val_loss: 2.2362 - val_accuracy: 0.2024 - 1s/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "610/610 - 1s - loss: 2.2405 - accuracy: 0.1921 - val_loss: 2.2219 - val_accuracy: 0.1982 - 1s/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "610/610 - 1s - loss: 2.2313 - accuracy: 0.1893 - val_loss: 2.2146 - val_accuracy: 0.2032 - 1s/epoch - 2ms/step\n",
      "Epoch 7/100\n",
      "610/610 - 1s - loss: 2.2212 - accuracy: 0.1971 - val_loss: 2.2096 - val_accuracy: 0.2058 - 1s/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "610/610 - 1s - loss: 2.2178 - accuracy: 0.1942 - val_loss: 2.2082 - val_accuracy: 0.2044 - 1s/epoch - 2ms/step\n",
      "Epoch 9/100\n",
      "610/610 - 1s - loss: 2.2126 - accuracy: 0.1936 - val_loss: 2.2042 - val_accuracy: 0.2038 - 1s/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "610/610 - 1s - loss: 2.2111 - accuracy: 0.1967 - val_loss: 2.2031 - val_accuracy: 0.2081 - 1s/epoch - 2ms/step\n",
      "Epoch 11/100\n",
      "610/610 - 1s - loss: 2.2083 - accuracy: 0.1968 - val_loss: 2.2023 - val_accuracy: 0.2062 - 1s/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "610/610 - 1s - loss: 2.2063 - accuracy: 0.1960 - val_loss: 2.1997 - val_accuracy: 0.2093 - 1s/epoch - 2ms/step\n",
      "Epoch 13/100\n",
      "610/610 - 1s - loss: 2.2037 - accuracy: 0.1937 - val_loss: 2.2000 - val_accuracy: 0.2033 - 1s/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "610/610 - 1s - loss: 2.2035 - accuracy: 0.1954 - val_loss: 2.1977 - val_accuracy: 0.2086 - 1s/epoch - 2ms/step\n",
      "Epoch 15/100\n",
      "610/610 - 1s - loss: 2.2028 - accuracy: 0.1958 - val_loss: 2.1965 - val_accuracy: 0.2073 - 1s/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "610/610 - 1s - loss: 2.1986 - accuracy: 0.1972 - val_loss: 2.1966 - val_accuracy: 0.2087 - 1s/epoch - 2ms/step\n",
      "Epoch 17/100\n",
      "610/610 - 1s - loss: 2.1991 - accuracy: 0.1959 - val_loss: 2.1951 - val_accuracy: 0.2059 - 1s/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "610/610 - 1s - loss: 2.1983 - accuracy: 0.1986 - val_loss: 2.1972 - val_accuracy: 0.2101 - 1s/epoch - 2ms/step\n",
      "Epoch 19/100\n",
      "610/610 - 1s - loss: 2.1971 - accuracy: 0.2032 - val_loss: 2.1933 - val_accuracy: 0.2076 - 1s/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "610/610 - 1s - loss: 2.1967 - accuracy: 0.1975 - val_loss: 2.1920 - val_accuracy: 0.2069 - 1s/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "610/610 - 1s - loss: 2.1928 - accuracy: 0.1990 - val_loss: 2.1924 - val_accuracy: 0.2112 - 1s/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "610/610 - 1s - loss: 2.1945 - accuracy: 0.1981 - val_loss: 2.1904 - val_accuracy: 0.2081 - 1s/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "610/610 - 1s - loss: 2.1903 - accuracy: 0.2021 - val_loss: 2.1907 - val_accuracy: 0.2058 - 1s/epoch - 2ms/step\n",
      "Epoch 24/100\n",
      "610/610 - 1s - loss: 2.1919 - accuracy: 0.2026 - val_loss: 2.1887 - val_accuracy: 0.2107 - 1s/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "610/610 - 1s - loss: 2.1910 - accuracy: 0.2011 - val_loss: 2.1880 - val_accuracy: 0.2089 - 1s/epoch - 2ms/step\n",
      "Epoch 26/100\n",
      "610/610 - 1s - loss: 2.1900 - accuracy: 0.2017 - val_loss: 2.1862 - val_accuracy: 0.2125 - 1s/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "610/610 - 1s - loss: 2.1884 - accuracy: 0.2049 - val_loss: 2.1856 - val_accuracy: 0.2116 - 1s/epoch - 2ms/step\n",
      "Epoch 28/100\n",
      "610/610 - 1s - loss: 2.1867 - accuracy: 0.2002 - val_loss: 2.1884 - val_accuracy: 0.2122 - 1s/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "610/610 - 1s - loss: 2.1861 - accuracy: 0.2066 - val_loss: 2.1846 - val_accuracy: 0.2153 - 1s/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "610/610 - 1s - loss: 2.1839 - accuracy: 0.2057 - val_loss: 2.1824 - val_accuracy: 0.2072 - 1s/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "610/610 - 1s - loss: 2.1837 - accuracy: 0.2074 - val_loss: 2.1823 - val_accuracy: 0.2155 - 1s/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "610/610 - 1s - loss: 2.1843 - accuracy: 0.2050 - val_loss: 2.1812 - val_accuracy: 0.2132 - 1s/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "610/610 - 1s - loss: 2.1824 - accuracy: 0.2058 - val_loss: 2.1815 - val_accuracy: 0.2086 - 1s/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "610/610 - 1s - loss: 2.1825 - accuracy: 0.2057 - val_loss: 2.1805 - val_accuracy: 0.2116 - 1s/epoch - 2ms/step\n",
      "Epoch 35/100\n",
      "610/610 - 1s - loss: 2.1785 - accuracy: 0.2079 - val_loss: 2.1791 - val_accuracy: 0.2106 - 1s/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "610/610 - 1s - loss: 2.1777 - accuracy: 0.2089 - val_loss: 2.1786 - val_accuracy: 0.2115 - 1s/epoch - 2ms/step\n",
      "Epoch 37/100\n",
      "610/610 - 1s - loss: 2.1796 - accuracy: 0.2058 - val_loss: 2.1801 - val_accuracy: 0.2147 - 1s/epoch - 2ms/step\n",
      "Epoch 38/100\n",
      "610/610 - 1s - loss: 2.1792 - accuracy: 0.2093 - val_loss: 2.1786 - val_accuracy: 0.2125 - 1s/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "610/610 - 1s - loss: 2.1755 - accuracy: 0.2111 - val_loss: 2.1762 - val_accuracy: 0.2116 - 1s/epoch - 2ms/step\n",
      "Epoch 40/100\n",
      "610/610 - 1s - loss: 2.1770 - accuracy: 0.2109 - val_loss: 2.1769 - val_accuracy: 0.2122 - 1s/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "610/610 - 1s - loss: 2.1760 - accuracy: 0.2090 - val_loss: 2.1754 - val_accuracy: 0.2142 - 1s/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "610/610 - 1s - loss: 2.1757 - accuracy: 0.2086 - val_loss: 2.1752 - val_accuracy: 0.2133 - 1s/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "610/610 - 1s - loss: 2.1739 - accuracy: 0.2101 - val_loss: 2.1745 - val_accuracy: 0.2118 - 1s/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "610/610 - 1s - loss: 2.1732 - accuracy: 0.2124 - val_loss: 2.1734 - val_accuracy: 0.2144 - 1s/epoch - 2ms/step\n",
      "Epoch 45/100\n",
      "610/610 - 1s - loss: 2.1747 - accuracy: 0.2072 - val_loss: 2.1733 - val_accuracy: 0.2136 - 1s/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "610/610 - 1s - loss: 2.1721 - accuracy: 0.2086 - val_loss: 2.1729 - val_accuracy: 0.2132 - 1s/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "610/610 - 1s - loss: 2.1720 - accuracy: 0.2108 - val_loss: 2.1726 - val_accuracy: 0.2149 - 1s/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "610/610 - 1s - loss: 2.1717 - accuracy: 0.2102 - val_loss: 2.1711 - val_accuracy: 0.2124 - 1s/epoch - 2ms/step\n",
      "Epoch 49/100\n",
      "610/610 - 1s - loss: 2.1712 - accuracy: 0.2124 - val_loss: 2.1721 - val_accuracy: 0.2139 - 1s/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "610/610 - 1s - loss: 2.1698 - accuracy: 0.2069 - val_loss: 2.1727 - val_accuracy: 0.2156 - 1s/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "610/610 - 1s - loss: 2.1687 - accuracy: 0.2108 - val_loss: 2.1700 - val_accuracy: 0.2149 - 1s/epoch - 2ms/step\n",
      "Epoch 52/100\n",
      "610/610 - 1s - loss: 2.1689 - accuracy: 0.2098 - val_loss: 2.1694 - val_accuracy: 0.2122 - 1s/epoch - 2ms/step\n",
      "Epoch 53/100\n",
      "610/610 - 1s - loss: 2.1682 - accuracy: 0.2120 - val_loss: 2.1701 - val_accuracy: 0.2152 - 1s/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "610/610 - 1s - loss: 2.1679 - accuracy: 0.2125 - val_loss: 2.1683 - val_accuracy: 0.2142 - 1s/epoch - 2ms/step\n",
      "Epoch 55/100\n",
      "610/610 - 1s - loss: 2.1669 - accuracy: 0.2158 - val_loss: 2.1687 - val_accuracy: 0.2167 - 1s/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "610/610 - 1s - loss: 2.1658 - accuracy: 0.2111 - val_loss: 2.1687 - val_accuracy: 0.2147 - 1s/epoch - 2ms/step\n",
      "Epoch 57/100\n",
      "610/610 - 1s - loss: 2.1666 - accuracy: 0.2131 - val_loss: 2.1670 - val_accuracy: 0.2145 - 1s/epoch - 2ms/step\n",
      "Epoch 58/100\n",
      "610/610 - 1s - loss: 2.1659 - accuracy: 0.2156 - val_loss: 2.1678 - val_accuracy: 0.2170 - 1s/epoch - 2ms/step\n",
      "Epoch 59/100\n",
      "610/610 - 1s - loss: 2.1635 - accuracy: 0.2121 - val_loss: 2.1665 - val_accuracy: 0.2144 - 1s/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "610/610 - 1s - loss: 2.1642 - accuracy: 0.2150 - val_loss: 2.1658 - val_accuracy: 0.2125 - 1s/epoch - 2ms/step\n",
      "Epoch 61/100\n",
      "610/610 - 1s - loss: 2.1637 - accuracy: 0.2152 - val_loss: 2.1649 - val_accuracy: 0.2152 - 1s/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "610/610 - 1s - loss: 2.1627 - accuracy: 0.2138 - val_loss: 2.1651 - val_accuracy: 0.2144 - 1s/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "610/610 - 1s - loss: 2.1629 - accuracy: 0.2134 - val_loss: 2.1651 - val_accuracy: 0.2162 - 1s/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "610/610 - 1s - loss: 2.1628 - accuracy: 0.2125 - val_loss: 2.1662 - val_accuracy: 0.2165 - 1s/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "610/610 - 1s - loss: 2.1630 - accuracy: 0.2122 - val_loss: 2.1642 - val_accuracy: 0.2162 - 1s/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "610/610 - 1s - loss: 2.1608 - accuracy: 0.2136 - val_loss: 2.1642 - val_accuracy: 0.2147 - 1s/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "610/610 - 1s - loss: 2.1606 - accuracy: 0.2140 - val_loss: 2.1625 - val_accuracy: 0.2135 - 1s/epoch - 2ms/step\n",
      "Epoch 68/100\n",
      "610/610 - 1s - loss: 2.1600 - accuracy: 0.2142 - val_loss: 2.1624 - val_accuracy: 0.2130 - 1s/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "610/610 - 1s - loss: 2.1611 - accuracy: 0.2167 - val_loss: 2.1629 - val_accuracy: 0.2173 - 1s/epoch - 2ms/step\n",
      "Epoch 70/100\n",
      "610/610 - 1s - loss: 2.1584 - accuracy: 0.2147 - val_loss: 2.1625 - val_accuracy: 0.2172 - 1s/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "610/610 - 1s - loss: 2.1581 - accuracy: 0.2160 - val_loss: 2.1632 - val_accuracy: 0.2155 - 1s/epoch - 2ms/step\n",
      "Epoch 72/100\n",
      "610/610 - 1s - loss: 2.1594 - accuracy: 0.2160 - val_loss: 2.1617 - val_accuracy: 0.2142 - 1s/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "610/610 - 1s - loss: 2.1568 - accuracy: 0.2134 - val_loss: 2.1609 - val_accuracy: 0.2158 - 1s/epoch - 2ms/step\n",
      "Epoch 74/100\n",
      "610/610 - 1s - loss: 2.1577 - accuracy: 0.2137 - val_loss: 2.1609 - val_accuracy: 0.2141 - 1s/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "610/610 - 1s - loss: 2.1562 - accuracy: 0.2148 - val_loss: 2.1606 - val_accuracy: 0.2153 - 1s/epoch - 2ms/step\n",
      "Epoch 76/100\n",
      "610/610 - 1s - loss: 2.1583 - accuracy: 0.2160 - val_loss: 2.1596 - val_accuracy: 0.2152 - 1s/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "610/610 - 1s - loss: 2.1574 - accuracy: 0.2161 - val_loss: 2.1601 - val_accuracy: 0.2175 - 1s/epoch - 2ms/step\n",
      "Epoch 78/100\n",
      "610/610 - 1s - loss: 2.1563 - accuracy: 0.2127 - val_loss: 2.1605 - val_accuracy: 0.2181 - 1s/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "610/610 - 1s - loss: 2.1543 - accuracy: 0.2168 - val_loss: 2.1596 - val_accuracy: 0.2165 - 1s/epoch - 2ms/step\n",
      "Epoch 80/100\n",
      "610/610 - 1s - loss: 2.1553 - accuracy: 0.2132 - val_loss: 2.1579 - val_accuracy: 0.2169 - 1s/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "610/610 - 1s - loss: 2.1546 - accuracy: 0.2187 - val_loss: 2.1590 - val_accuracy: 0.2169 - 1s/epoch - 2ms/step\n",
      "Epoch 82/100\n",
      "610/610 - 1s - loss: 2.1562 - accuracy: 0.2154 - val_loss: 2.1576 - val_accuracy: 0.2179 - 1s/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "610/610 - 1s - loss: 2.1541 - accuracy: 0.2156 - val_loss: 2.1581 - val_accuracy: 0.2209 - 1s/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "610/610 - 1s - loss: 2.1535 - accuracy: 0.2171 - val_loss: 2.1579 - val_accuracy: 0.2179 - 1s/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "610/610 - 1s - loss: 2.1542 - accuracy: 0.2167 - val_loss: 2.1579 - val_accuracy: 0.2192 - 1s/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "610/610 - 1s - loss: 2.1540 - accuracy: 0.2171 - val_loss: 2.1559 - val_accuracy: 0.2187 - 1s/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "610/610 - 1s - loss: 2.1539 - accuracy: 0.2174 - val_loss: 2.1569 - val_accuracy: 0.2202 - 1s/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "610/610 - 1s - loss: 2.1506 - accuracy: 0.2166 - val_loss: 2.1611 - val_accuracy: 0.2198 - 1s/epoch - 2ms/step\n",
      "Epoch 89/100\n",
      "610/610 - 1s - loss: 2.1523 - accuracy: 0.2188 - val_loss: 2.1573 - val_accuracy: 0.2187 - 1s/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "610/610 - 1s - loss: 2.1520 - accuracy: 0.2173 - val_loss: 2.1587 - val_accuracy: 0.2172 - 1s/epoch - 2ms/step\n",
      "Epoch 91/100\n",
      "610/610 - 1s - loss: 2.1505 - accuracy: 0.2185 - val_loss: 2.1567 - val_accuracy: 0.2184 - 1s/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "610/610 - 1s - loss: 2.1514 - accuracy: 0.2163 - val_loss: 2.1563 - val_accuracy: 0.2198 - 1s/epoch - 2ms/step\n",
      "Epoch 93/100\n",
      "610/610 - 1s - loss: 2.1504 - accuracy: 0.2171 - val_loss: 2.1551 - val_accuracy: 0.2196 - 1s/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "610/610 - 1s - loss: 2.1493 - accuracy: 0.2196 - val_loss: 2.1542 - val_accuracy: 0.2179 - 1s/epoch - 2ms/step\n",
      "Epoch 95/100\n",
      "610/610 - 1s - loss: 2.1487 - accuracy: 0.2183 - val_loss: 2.1539 - val_accuracy: 0.2207 - 1s/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "610/610 - 1s - loss: 2.1478 - accuracy: 0.2192 - val_loss: 2.1551 - val_accuracy: 0.2207 - 1s/epoch - 2ms/step\n",
      "Epoch 97/100\n",
      "610/610 - 1s - loss: 2.1478 - accuracy: 0.2202 - val_loss: 2.1537 - val_accuracy: 0.2185 - 1s/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "610/610 - 1s - loss: 2.1485 - accuracy: 0.2186 - val_loss: 2.1546 - val_accuracy: 0.2213 - 1s/epoch - 2ms/step\n",
      "Epoch 99/100\n",
      "610/610 - 1s - loss: 2.1487 - accuracy: 0.2182 - val_loss: 2.1540 - val_accuracy: 0.2201 - 1s/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "610/610 - 1s - loss: 2.1479 - accuracy: 0.2198 - val_loss: 2.1542 - val_accuracy: 0.2199 - 1s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x290bbc4d1f0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = classification_model_multi()\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val,), epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model.predict(X_test)\n",
    "y_pred =np.argmax(value,axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       579\n",
      "           1       0.00      0.00      0.00       536\n",
      "           2       0.00      0.00      0.00       636\n",
      "           3       0.12      0.01      0.02       641\n",
      "           4       0.18      0.05      0.08      1120\n",
      "           5       0.17      0.50      0.25      1164\n",
      "           6       0.00      0.00      0.00       741\n",
      "           7       0.23      0.12      0.16       803\n",
      "           8       0.00      0.00      0.00        46\n",
      "           9       0.00      0.00      0.00         3\n",
      "          10       0.00      0.00      0.00         3\n",
      "          11       0.00      0.00      0.00         3\n",
      "          12       0.00      0.00      0.00      1066\n",
      "          13       0.22      0.80      0.35      1249\n",
      "          14       0.00      0.00      0.00        17\n",
      "          15       0.00      0.00      0.00        62\n",
      "\n",
      "    accuracy                           0.20      8669\n",
      "   macro avg       0.06      0.09      0.05      8669\n",
      "weighted avg       0.11      0.20      0.11      8669\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value = model.predict(X_test)\n",
    "y_pred = np.argmax(value,axis=1)\n",
    "y_true = np.argmax(y_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len :  8669\n",
      "Final Score : 1739/8669\n",
      "Accuracy :  20.059983850501787\n"
     ]
    }
   ],
   "source": [
    "y_pred_arr = list(y_pred)\n",
    "print(\"len : \", len(y_pred_arr))\n",
    "score = 0\n",
    "for i in range(len(y_pred_arr)):\n",
    "    if(list(y_pred)[i] == list(y_true)[i]): score += 1\n",
    "max_score = len(list(y_pred))\n",
    "print(f\"Final Score : {score}/{max_score}\")\n",
    "print(\"Accuracy : \", 100 * score / max_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Process #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import odeint\n",
    "# Parameters and time for FOPDT model\n",
    "ns = 10000\n",
    "t = np.linspace(0,ns-1,ns)\n",
    "u = np.zeros(ns)\n",
    "# Additional FOPDT parameters\n",
    "yp0 = 0.0\n",
    "u0 = u[0]\n",
    "Km = 0.67\n",
    "taum = 160.0\n",
    "def fopdt(y,t,um,Km,taum):\n",
    "    # arguments\n",
    "    #  y      = output\n",
    "    #  t      = time\n",
    "    #  uf     = input linear function (for time shift)\n",
    "    #  Km     = model gain\n",
    "    #  taum   = model time constant\n",
    "    # calculate derivative\n",
    "    dydt = (-(y-yp0) + Km * (um-u0))/taum\n",
    "    return dydt\n",
    "\n",
    "def sim_model(Km,taum):\n",
    "    # array for model values\n",
    "    ym = np.zeros(ns)\n",
    "    # initial condition\n",
    "    ym[0] = yp0\n",
    "    # loop through time steps    \n",
    "    for i in range(0,ns-1):\n",
    "        ts = [t[i],t[i+1]]\n",
    "        y1 = odeint(fopdt,ym[i],ts,args=(u[i],Km,taum))\n",
    "        ym[i+1] = y1[-1]\n",
    "    return ym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "end = 60 # leave 1st minute of u as 0\n",
    "while end <= ns:\n",
    "    start = end\n",
    "    end += random.randint(300,900) # keep new Q1s value for anywhere from 5 to 15 minutes\n",
    "    u[start:end] = random.randint(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate FOPDT model\n",
    "y = sim_model(Km,taum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Gaussian noise\n",
    "noise = np.random.normal(0,0.2,ns)\n",
    "y += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Scale data\n",
    "data = np.vstack((u,y)).T\n",
    "s = MinMaxScaler(feature_range=(0,1))\n",
    "data_s = s.fit_transform(data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
